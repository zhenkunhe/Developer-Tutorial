<!DOCTYPE html>
<!-- saved from url=(0110)http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb# -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

    <title>Object detection</title>
    <link rel="shortcut icon" type="image/x-icon" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/static/base/images/favicon.ico?v=30780f272ab4aac64aa073a841546240">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="stylesheet" href="./Object detection_files/jquery-ui.min.css" type="text/css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    


<script type="text/javascript" src="./Object detection_files/MathJax.js" charset="utf-8"></script>

<script type="text/javascript">
// MathJax disabled, set as null to distingish from *missing* MathJax,
// where it will be undefined, and should prompt a dialog later.
window.mathjax_url = "/6pfqVNhz7HDt/static/mathjax/MathJax.js";
</script>

<link rel="stylesheet" href="./Object detection_files/bootstrap-tour.min.css" type="text/css">
<link rel="stylesheet" href="./Object detection_files/codemirror.css">


    <link rel="stylesheet" href="./Object detection_files/style.min.css" type="text/css">
    

<link rel="stylesheet" href="./Object detection_files/override.css" type="text/css">
<link rel="stylesheet" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb" id="kernel-css" type="text/css">


    <link rel="stylesheet" href="./Object detection_files/custom.css" type="text/css">
    <script src="./Object detection_files/promise.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="./Object detection_files/require.js" type="text/javascript" charset="utf-8"></script>
    <script>
      require.config({
          
          urlArgs: "v=20161021061339",
          
          baseUrl: '/6pfqVNhz7HDt/static/',
          paths: {
            nbextensions : '/6pfqVNhz7HDt/nbextensions',
            kernelspecs : '/6pfqVNhz7HDt/kernelspecs',
            underscore : 'components/underscore/underscore-min',
            backbone : 'components/backbone/backbone-min',
            jquery: 'components/jquery/jquery.min',
            bootstrap: 'components/bootstrap/js/bootstrap.min',
            bootstraptour: 'components/bootstrap-tour/build/js/bootstrap-tour.min',
            jqueryui: 'components/jquery-ui/ui/minified/jquery-ui.min',
            moment: 'components/moment/moment',
            codemirror: 'components/codemirror',
            termjs: 'components/term.js/src/term',
          },
          shim: {
            underscore: {
              exports: '_'
            },
            backbone: {
              deps: ["underscore", "jquery"],
              exports: "Backbone"
            },
            bootstrap: {
              deps: ["jquery"],
              exports: "bootstrap"
            },
            bootstraptour: {
              deps: ["bootstrap"],
              exports: "Tour"
            },
            jqueryui: {
              deps: ["jquery"],
              exports: "$"
            }
          }
      });

      require.config({
          map: {
              '*':{
                'contents': 'services/contents',
              }
          }
      });
    </script>

    
    

<script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/namespace" src="./Object detection_files/namespace.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="jquery" src="./Object detection_files/jquery.min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/notebook" src="./Object detection_files/notebook.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/contents" src="./Object detection_files/contents.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/config" src="./Object detection_files/config.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/utils" src="./Object detection_files/utils.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/page" src="./Object detection_files/page.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/events" src="./Object detection_files/events.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="auth/js/loginwidget" src="./Object detection_files/loginwidget.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/maintoolbar" src="./Object detection_files/maintoolbar.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/pager" src="./Object detection_files/pager.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/quickhelp" src="./Object detection_files/quickhelp.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/menubar" src="./Object detection_files/menubar.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/notificationarea" src="./Object detection_files/notificationarea.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/savewidget" src="./Object detection_files/savewidget.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/actions" src="./Object detection_files/actions.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/keyboardmanager" src="./Object detection_files/keyboardmanager.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/kernelselector" src="./Object detection_files/kernelselector.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/lib/codemirror" src="./Object detection_files/codemirror.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/about" src="./Object detection_files/about.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="custom/custom" src="./Object detection_files/custom.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="moment" src="./Object detection_files/moment.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/meta" src="./Object detection_files/meta.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/dialog" src="./Object detection_files/dialog.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/cell" src="./Object detection_files/cell.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/textcell" src="./Object detection_files/textcell.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/codecell" src="./Object detection_files/codecell.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/sessions/session" src="./Object detection_files/session.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/celltoolbar" src="./Object detection_files/celltoolbar.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="components/marked/lib/marked" src="./Object detection_files/marked.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/runmode/runmode" src="./Object detection_files/runmode.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/mathjaxutils" src="./Object detection_files/mathjaxutils.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/keyboard" src="./Object detection_files/keyboard.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/tooltip" src="./Object detection_files/tooltip.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/celltoolbarpresets/default" src="./Object detection_files/default.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/celltoolbarpresets/rawcell" src="./Object detection_files/rawcell.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/celltoolbarpresets/slideshow" src="./Object detection_files/slideshow.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/scrollmanager" src="./Object detection_files/scrollmanager.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/toolbar" src="./Object detection_files/toolbar.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="jqueryui" src="./Object detection_files/jquery-ui.min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/tour" src="./Object detection_files/tour.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/notificationarea" src="./Object detection_files/notificationarea(1).js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/edit/matchbrackets" src="./Object detection_files/matchbrackets.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/edit/closebrackets" src="./Object detection_files/closebrackets.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/comment/comment" src="./Object detection_files/comment.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/security" src="./Object detection_files/security.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/gfm/gfm" src="./Object detection_files/gfm.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/codemirror-ipythongfm" src="./Object detection_files/codemirror-ipythongfm.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/outputarea" src="./Object detection_files/outputarea.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/completer" src="./Object detection_files/completer.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/python/python" src="./Object detection_files/python.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/codemirror-ipython" src="./Object detection_files/codemirror-ipython.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/kernels/kernel" src="./Object detection_files/kernel.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="bootstrap" src="./Object detection_files/bootstrap.min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/notificationwidget" src="./Object detection_files/notificationwidget.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="underscore" src="./Object detection_files/underscore-min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="components/google-caja/html-css-sanitizer-minified" src="./Object detection_files/html-css-sanitizer-minified.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/markdown/markdown" src="./Object detection_files/markdown.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/mode/overlay" src="./Object detection_files/overlay.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/mode/multiplex" src="./Object detection_files/multiplex.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/stex/stex" src="./Object detection_files/stex.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/contexthint" src="./Object detection_files/contexthint.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/kernels/comm" src="./Object detection_files/comm.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/kernels/serialize" src="./Object detection_files/serialize.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/init" src="./Object detection_files/init.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="bootstraptour" src="./Object detection_files/bootstrap-tour.min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/xml/xml" src="./Object detection_files/xml.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/manager" src="./Object detection_files/manager.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_link" src="./Object detection_files/widget_link.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_bool" src="./Object detection_files/widget_bool.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_button" src="./Object detection_files/widget_button.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_box" src="./Object detection_files/widget_box.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_float" src="./Object detection_files/widget_float.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_image" src="./Object detection_files/widget_image.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_int" src="./Object detection_files/widget_int.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_output" src="./Object detection_files/widget_output.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_selection" src="./Object detection_files/widget_selection.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_selectioncontainer" src="./Object detection_files/widget_selectioncontainer.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_string" src="./Object detection_files/widget_string.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget" src="./Object detection_files/widget.js"></script><style id="style-1-cropbar-clipper">/* Copyright 2014 Evernote Corporation. All rights reserved. */
.en-markup-crop-options {
    top: 18px !important;
    left: 50% !important;
    margin-left: -100px !important;
    width: 200px !important;
    border: 2px rgba(255,255,255,.38) solid !important;
    border-radius: 4px !important;
}

.en-markup-crop-options div div:first-of-type {
    margin-left: 0px !important;
}
</style><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="backbone" src="./Object detection_files/backbone-min.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Hover_Arrow {position: absolute; width: 15px; height: 11px; cursor: pointer}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; color: #666666}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_Menu_Close {position: absolute; width: 31px; height: 31px; top: -15px; left: -15px}
</style><style type="text/css">.MathJax_Preview .MJXc-math {color: inherit!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXc-script {font-size: .8em}
.MJXc-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXc-bold {font-weight: bold}
.MJXc-italic {font-style: italic}
.MJXc-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-largeop {font-size: 150%}
.MJXc-largeop.MJXc-int {vertical-align: -.2em}
.MJXc-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXc-display {display: block; text-align: center; margin: 1em 0}
.MJXc-math span {display: inline-block}
.MJXc-box {display: block!important; text-align: center}
.MJXc-box:after {content: " "}
.MJXc-rule {display: block!important; margin-top: .1em}
.MJXc-char {display: block!important}
.MJXc-mo {margin: 0 .15em}
.MJXc-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXc-denom {display: inline-table!important; width: 100%}
.MJXc-denom > * {display: table-row!important}
.MJXc-surd {vertical-align: top}
.MJXc-surd > * {display: block!important}
.MJXc-script-box > *  {display: table!important; height: 50%}
.MJXc-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXc-script-box > *:last-child > * {vertical-align: bottom}
.MJXc-script-box > * > * > * {display: block!important}
.MJXc-mphantom {visibility: hidden}
.MJXc-munderover {display: inline-table!important}
.MJXc-over {display: inline-block!important; text-align: center}
.MJXc-over > * {display: block!important}
.MJXc-munderover > * {display: table-row!important}
.MJXc-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXc-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXc-mtr {display: table-row!important}
.MJXc-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXc-mtr > .MJXc-mtd:first-child {padding-left: 0}
.MJXc-mtr:first-child > .MJXc-mtd {padding-top: 0}
.MJXc-mlabeledtr {display: table-row!important}
.MJXc-mlabeledtr > .MJXc-mtd:first-child {padding-left: 0}
.MJXc-mlabeledtr:first-child > .MJXc-mtd {padding-top: 0}
.MJXc-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXc-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXc-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXc-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXc-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXc-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXc-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXc-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXc-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXc-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXc-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_CHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 0; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>

<body class="notebook_app command_mode" data-project="" data-base-url="/6pfqVNhz7HDt/" data-ws-url="" data-notebook-name="Object%20detection.ipynb" data-notebook-path="Object%20detection.ipynb" data-pinterest-extension-installed="cr2.0.4" style=""><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"><br></div></div><div id="MathJax_Message" style="display: none;"></div>

<noscript>
    &lt;div id='noscript'&gt;
      IPython Notebook requires JavaScript.&lt;br&gt;
      Please enable it to proceed.
  &lt;/div&gt;
</noscript>

<div id="header" style="display: block;">
  <div id="header-container" class="container">
  <div id="ipython_notebook" class="nav navbar-brand pull-left"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/tree" title="dashboard"><img src="./Object detection_files/logo.png" alt="Jupyter Notebook" data-pin-nopin="true"></a></div>

  

  

    <span id="login_widget">
      
    </span>

  

  

  


<span id="save_widget" class="pull-left save_widget">
    <span id="notebook_name" class="filename" data-vivaldi-spatnav-clickable="1">Object detection</span>
    <span class="checkpoint_status" title="Fri, Oct 21, 2016 4:20 PM">Last Checkpoint: a minute ago</span>
    <span class="autosave_status">(autosaved)</span>
</span>

<span id="kernel_logo_widget">
  <img class="current_kernel_logo" src="./Object detection_files/logo-64x64.png" style="display: inline;">
</span>


  </div>
  <div class="header-bar"></div>

  
<div id="menubar-container" class="container">
<div id="menubar">
    <div id="menus" class="navbar navbar-default" role="navigation">
        <div class="container-fluid">
            <button type="button" class="btn btn-default navbar-btn navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <i class="fa fa-bars"></i>
              <span class="navbar-text">Menu</span>
            </button>
            <p id="kernel_indicator" class="navbar-text indicator_area">
              <span class="kernel_indicator_name">Python 2</span>
              <i id="kernel_indicator_icon" class="kernel_idle_icon" title="Kernel Idle"></i>
            </p>
            <i id="readonly-indicator" class="navbar-text" title="This notebook is read-only" style="display: none;">
                <span class="fa-stack">
                    <i class="fa fa-save fa-stack-1x"></i>
                    <i class="fa fa-ban fa-stack-2x text-danger"></i>
                </span>
            </i>
            <i id="modal_indicator" class="navbar-text modal_indicator" title="Command Mode"></i>
            <span id="notification_area"><div id="notification_kernel" class="notification_widget btn btn-xs navbar-btn undefined info" data-vivaldi-spatnav-clickable="1" style="display: none;"><span></span></div><div id="notification_notebook" class="notification_widget btn btn-xs navbar-btn" data-vivaldi-spatnav-clickable="1" style="display: none;"><span></span></div></span>
            <div class="navbar-collapse collapse">
              <ul class="nav navbar-nav">
                <li class="dropdown" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" class="dropdown-toggle" data-toggle="dropdown" aria-expanded="false">File</a>
                    <ul id="file_menu" class="dropdown-menu">
                        <li id="new_notebook" class="dropdown-submenu" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">New Notebook</a>
                            <ul class="dropdown-menu" id="menu-new-notebook-submenu"><li id="new-notebook-submenu-python2"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" data-vivaldi-spatnav-clickable="1">Python 2</a></li><li class="divider"></li><li id="new-notebook-submenu-itorch"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" data-vivaldi-spatnav-clickable="1">iTorch</a></li></ul>
                        </li>
                        <li id="open_notebook" title="Opens a new window with the Dashboard view" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Open...</a></li>
                        <!-- <hr/> -->
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="copy_notebook" title="Open a copy of this notebook&#39;s contents and start a new kernel" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Make a Copy...</a></li>
                        <li id="rename_notebook" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Rename...</a></li>
                        <li id="save_checkpoint" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Save and Checkpoint</a></li>
                        <!-- <hr/> -->
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="restore_checkpoint" class="dropdown-submenu" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Revert to Checkpoint</a>
                          <ul class="dropdown-menu"><li><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" data-vivaldi-spatnav-clickable="1">Friday, October 21, 2016 4:20 PM</a></li></ul>
                        </li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="print_preview" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Print Preview</a></li>
                        <li class="dropdown-submenu" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Download as</a>
                            <ul class="dropdown-menu">
                                <li id="download_ipynb" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">IPython Notebook (.ipynb)</a></li>
                                <li id="download_script" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Python (.py)</a></li>
                                <li id="download_html" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">HTML (.html)</a></li>
                                <li id="download_markdown" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Markdown (.md)</a></li>
                                <li id="download_rst" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">reST (.rst)</a></li>
                                <li id="download_pdf" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">PDF via LaTeX (.pdf)</a></li>
                            </ul>
                        </li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="trust_notebook" title="Trust the output of this notebook" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Trust Notebook</a></li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="kill_and_exit" title="Shutdown this notebook&#39;s kernel, and close this window" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Close and Halt</a></li>
                    </ul>
                </li>
                <li class="dropdown" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Edit</a>
                    <ul id="edit_menu" class="dropdown-menu">
                        <li id="cut_cell" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Cut Cell</a></li>
                        <li id="copy_cell" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Copy Cell</a></li>
                        <li id="paste_cell_above" class="disabled" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Paste Cell Above</a></li>
                        <li id="paste_cell_below" class="disabled" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Paste Cell Below</a></li>
                        <li id="paste_cell_replace" class="disabled" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Paste Cell &amp; Replace</a></li>
                        <li id="delete_cell" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Delete Cell</a></li>
                        <li id="undelete_cell" class="disabled" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Undo Delete Cell</a></li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="split_cell" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Split Cell</a></li>
                        <li id="merge_cell_above" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Merge Cell Above</a></li>
                        <li id="merge_cell_below" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Merge Cell Below</a></li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="move_cell_up" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Move Cell Up</a></li>
                        <li id="move_cell_down" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Move Cell Down</a></li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="edit_nb_metadata" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Edit Notebook Metadata</a></li>
                    </ul>
                </li>
                <li class="dropdown" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" class="dropdown-toggle" data-toggle="dropdown">View</a>
                    <ul id="view_menu" class="dropdown-menu">
                        <li id="toggle_header" title="Show/Hide the IPython Notebook logo and notebook title (above menu bar)" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Toggle Header</a></li>
                        <li id="toggle_toolbar" title="Show/Hide the action icons (below menu bar)" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Toggle Toolbar</a></li>
                    </ul>
                </li>
                <li class="dropdown" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Insert</a>
                    <ul id="insert_menu" class="dropdown-menu">
                        <li id="insert_cell_above" title="Insert an empty Code cell above the currently active cell" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Insert Cell Above</a></li>
                        <li id="insert_cell_below" title="Insert an empty Code cell below the currently active cell" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Insert Cell Below</a></li>
                    </ul>
                </li>
                <li class="dropdown" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Cell</a>
                    <ul id="cell_menu" class="dropdown-menu">
                        <li id="run_cell" title="Run this cell, and move cursor to the next one" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Run</a></li>
                        <li id="run_cell_select_below" title="Run this cell, select below" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Run and Select Below</a></li>
                        <li id="run_cell_insert_below" title="Run this cell, insert below" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Run and Insert Below</a></li>
                        <li id="run_all_cells" title="Run all cells in the notebook" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Run All</a></li>
                        <li id="run_all_cells_above" title="Run all cells above (but not including) this cell" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Run All Above</a></li>
                        <li id="run_all_cells_below" title="Run this cell and all cells below it" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Run All Below</a></li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="change_cell_type" class="dropdown-submenu" title="All cells in the notebook have a cell type. By default, new cells are created as &#39;Code&#39; cells" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Cell Type</a>
                            <ul class="dropdown-menu">
                              <li id="to_code" title="Contents will be sent to the kernel for execution, and output will display in the footer of cell" data-vivaldi-spatnav-clickable="1">
                                  <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Code</a></li>
                              <li id="to_markdown" title="Contents will be rendered as HTML and serve as explanatory text" data-vivaldi-spatnav-clickable="1">
                                  <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Markdown</a></li>
                              <li id="to_raw" title="Contents will pass through nbconvert unmodified" data-vivaldi-spatnav-clickable="1">
                                  <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Raw NBConvert</a></li>
                            </ul>
                        </li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="current_outputs" class="dropdown-submenu" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Current Output</a>
                            <ul class="dropdown-menu">
                                <li id="toggle_current_output" title="Hide/Show the output of the current cell" data-vivaldi-spatnav-clickable="1">
                                    <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Toggle</a>
                                </li>
                                <li id="toggle_current_output_scroll" title="Scroll the output of the current cell" data-vivaldi-spatnav-clickable="1">
                                    <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Toggle Scrolling</a>
                                </li>
                                <li id="clear_current_output" title="Clear the output of the current cell" data-vivaldi-spatnav-clickable="1">
                                    <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Clear</a>
                                </li>
                            </ul>
                        </li>
                        <li id="all_outputs" class="dropdown-submenu" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">All Output</a>
                            <ul class="dropdown-menu">
                                <li id="toggle_all_output" title="Hide/Show the output of all cells" data-vivaldi-spatnav-clickable="1">
                                    <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Toggle</a>
                                </li>
                                <li id="toggle_all_output_scroll" title="Scroll the output of all cells" data-vivaldi-spatnav-clickable="1">
                                    <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Toggle Scrolling</a>
                                </li>
                                <li id="clear_all_output" title="Clear the output of all cells" data-vivaldi-spatnav-clickable="1">
                                    <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Clear</a>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Kernel</a>
                    <ul id="kernel_menu" class="dropdown-menu">
                        <li id="int_kernel" title="Send KeyboardInterrupt (CTRL-C) to the Kernel" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Interrupt</a>
                        </li>
                        <li id="restart_kernel" title="Restart the Kernel" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Restart</a>
                        </li>
                        <li id="reconnect_kernel" title="Reconnect to the Kernel" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Reconnect</a>
                        </li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li id="menu-change-kernel" class="dropdown-submenu" data-vivaldi-spatnav-clickable="1">
                            <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Change kernel</a>
                            <ul class="dropdown-menu" id="menu-change-kernel-submenu"><li id="kernel-submenu-python2"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" data-vivaldi-spatnav-clickable="1">Python 2</a></li><li id="kernel-submenu-itorch"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" data-vivaldi-spatnav-clickable="1">iTorch</a></li></ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Help</a>
                    <ul id="help_menu" class="dropdown-menu">
                        <li id="notebook_tour" title="A quick tour of the notebook user interface" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">User Interface Tour</a></li>
                        <li id="keyboard_shortcuts" title="Opens a tooltip with all keyboard shortcuts" data-vivaldi-spatnav-clickable="1"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">Keyboard Shortcuts</a></li>
                        <li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        

                        
                            
                                <li data-vivaldi-spatnav-clickable="1"><a href="http://nbviewer.ipython.org/github/ipython/ipython/blob/3.x/examples/Notebook/Index.ipynb" target="_blank" title="Opens in a new window">
                                <i class="fa fa-external-link menu-icon pull-right"></i>
                                Notebook Help
                                </a></li>
                            
                                <li data-vivaldi-spatnav-clickable="1"><a href="https://help.github.com/articles/markdown-basics/" target="_blank" title="Opens in a new window">
                                <i class="fa fa-external-link menu-icon pull-right"></i>
                                Markdown
                                </a></li>
                            
                            
                        
                        <li id="kernel-help-links" class="divider"></li><li><a target="_blank" title="Opens in a new window" href="http://docs.python.org/2.7"><i class="fa fa-external-link menu-icon pull-right"></i><span>Python</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://ipython.org/documentation.html"><i class="fa fa-external-link menu-icon pull-right"></i><span>IPython</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.scipy.org/doc/numpy/reference/"><i class="fa fa-external-link menu-icon pull-right"></i><span>NumPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.scipy.org/doc/scipy/reference/"><i class="fa fa-external-link menu-icon pull-right"></i><span>SciPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://matplotlib.org/contents.html"><i class="fa fa-external-link menu-icon pull-right"></i><span>Matplotlib</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.sympy.org/latest/index.html"><i class="fa fa-external-link menu-icon pull-right"></i><span>SymPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://pandas.pydata.org/pandas-docs/stable/"><i class="fa fa-external-link menu-icon pull-right"></i><span>pandas</span></a></li><li class="divider" data-vivaldi-spatnav-clickable="1"></li>
                        <li title="About IPython Notebook" data-vivaldi-spatnav-clickable="1"><a id="notebook_about" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#">About</a></li>
                    </ul>
                </li>
              </ul>
            </div>
        </div>
    </div>
</div>

<div id="maintoolbar" class="navbar">
  <div class="toolbar-inner navbar-inner navbar-nobg">
    <div id="maintoolbar-container" class="container toolbar"><div class="btn-group" id="save-notbook"><button class="btn btn-default" title="Save and Checkpoint" data-jupyter-action="ipython.save-notebook" data-vivaldi-spatnav-clickable="1"><i class="fa-save fa"></i></button></div><div class="btn-group" id="insert_above_below"><button class="btn btn-default" title="insert cell below" data-jupyter-action="ipython.insert-cell-after" data-vivaldi-spatnav-clickable="1"><i class="fa-plus fa"></i></button></div><div class="btn-group" id="cut_copy_paste"><button class="btn btn-default" title="cut selected cell" data-jupyter-action="ipython.cut-selected-cell" data-vivaldi-spatnav-clickable="1"><i class="fa-cut fa"></i></button><button class="btn btn-default" title="copy selected cell" data-jupyter-action="ipython.copy-selected-cell" data-vivaldi-spatnav-clickable="1"><i class="fa-copy fa"></i></button><button class="btn btn-default" title="paste cell below" data-jupyter-action="ipython.paste-cell-after" data-vivaldi-spatnav-clickable="1"><i class="fa-paste fa"></i></button></div><div class="btn-group" id="move_up_down"><button class="btn btn-default" title="move selected cell up" data-jupyter-action="ipython.move-selected-cell-up" data-vivaldi-spatnav-clickable="1"><i class="fa-arrow-up fa"></i></button><button class="btn btn-default" title="move selected cell down" data-jupyter-action="ipython.move-selected-cell-down" data-vivaldi-spatnav-clickable="1"><i class="fa-arrow-down fa"></i></button></div><div class="btn-group" id="run_int"><button class="btn btn-default" title="run cell, select below" data-jupyter-action="ipython.run-select-next" data-vivaldi-spatnav-clickable="1"><i class="fa-play fa"></i></button><button class="btn btn-default" title="interrupt kernel" data-jupyter-action="ipython.interrupt-kernel" data-vivaldi-spatnav-clickable="1"><i class="fa-stop fa"></i></button><button class="btn btn-default" title="restart kernel" data-jupyter-action="ipython.restart-kernel" data-vivaldi-spatnav-clickable="1"><i class="fa-repeat fa"></i></button></div><select id="cell_type" class="form-control select-xs"><option value="code">Code</option><option value="markdown">Markdown</option><option value="raw">Raw NBConvert</option><option value="heading">Heading</option></select><div class="btn-group"><span class="navbar-text">Cell Toolbar:</span><select id="ctb_select" class="form-control select-xs"><option value="">None</option><option value="Edit Metadata">Edit Metadata</option><option value="Raw Cell Format">Raw Cell Format</option><option value="Slideshow">Slideshow</option></select></div></div>
  </div>
</div>
</div>

<div class="lower-header-bar"></div>

</div>

<div id="site" style="display: block; height: 621px;">


<div id="ipython-main-app">
    <div id="notebook_panel">
        <div id="notebook" tabindex="-1"><div class="container" id="notebook-container"><div class="cell text_cell rendered unselected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 322px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 22px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-1"># Overview</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In this notebook we will work through multiple examples of how to use DIGITS and Caffe to detect objects in aerial imagery.  The specific example used is inspired by the NOAA Right Whale Recognition competition (<span class="cm-link">https://www.kaggle.com/c/noaa-right-whale-recognition</span>) in which contestants were asked to identify the specific whale present in aerial images of the ocean.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Fig 1 shows an example image containing a mother whale and calf:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![Right whale example]</span><span class="cm-string">(right_whale_example.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">h4</span> <span class="cm-attribute">align</span>=<span class="cm-string">"center"</span><span class="cm-tag cm-bracket">&gt;</span>Figure 1: Mother Right Whale and calf<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">h4</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">We are going to tackle a slightly different problem though.  Rather than trying to identify which whale is present, we are going to train a convolutional neural network (CNN) to localize the whale within the image.  In the case where there may or may not be a whale present at all this problem is sometimes called object detection.  Many successful competitors in the original competition found it improved their scores to first detect and localize the whales in the image before trying to identify them using a cropped and normalized image.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 322px;"></div><div class="CodeMirror-gutters" style="display: none; height: 337px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h1 id="Overview">Overview<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Overview">¶</a></h1>
<p>In this notebook we will work through multiple examples of how to use DIGITS and Caffe to detect objects in aerial imagery.  The specific example used is inspired by the NOAA Right Whale Recognition competition (<a href="https://www.kaggle.com/c/noaa-right-whale-recognition" target="_blank">https://www.kaggle.com/c/noaa-right-whale-recognition</a>) in which contestants were asked to identify the specific whale present in aerial images of the ocean.  </p>
<p>Fig 1 shows an example image containing a mother whale and calf:</p>
<p><img src="./Object detection_files/right_whale_example.png" alt="Right whale example"></p>
<h4 align="center" id="Figure-1:-Mother-Right-Whale-and-calf">Figure 1: Mother Right Whale and calf<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Figure-1:-Mother-Right-Whale-and-calf">¶</a></h4> 


<p>We are going to tackle a slightly different problem though.  Rather than trying to identify which whale is present, we are going to train a convolutional neural network (CNN) to localize the whale within the image.  In the case where there may or may not be a whale present at all this problem is sometimes called object detection.  Many successful competitors in the original competition found it improved their scores to first detect and localize the whales in the image before trying to identify them using a cropped and normalized image.</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 150px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Object detection approach 1:  sliding window</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">There are multiple ways to detect and localize objects in images using convolutional neural networks (CNN).  The simplest approach is to first train a CNN classifier on image patches that can differentiate the object from non-object examples.  Fig 2 shows the architecture of a CNN that can distinguish whale patches from background patches.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![patch based model]</span><span class="cm-string">(patch_based.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">h4</span> <span class="cm-attribute">align</span>=<span class="cm-string">"center"</span><span class="cm-tag cm-bracket">&gt;</span>Figure 2: Patch based training of a CNN classifier<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">h4</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 150px;"></div><div class="CodeMirror-gutters" style="display: none; height: 165px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Object-detection-approach-1:--sliding-window">Object detection approach 1:  sliding window<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Object-detection-approach-1:--sliding-window">¶</a></h2>
<p>There are multiple ways to detect and localize objects in images using convolutional neural networks (CNN).  The simplest approach is to first train a CNN classifier on image patches that can differentiate the object from non-object examples.  Fig 2 shows the architecture of a CNN that can distinguish whale patches from background patches.</p>
<p><img src="./Object detection_files/patch_based.png" alt="patch based model"></p>
<h4 align="center" id="Figure-2:-Patch-based-training-of-a-CNN-classifier">Figure 2: Patch based training of a CNN classifier<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Figure-2:-Patch-based-training-of-a-CNN-classifier">¶</a></h4> </div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 1135px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 16.5px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;">Armed with this type of classifier we can then inspect each patch in a larger image, possibly using overlapping patches, and make a determination whether there is a whale present.  So let's do that.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">For this notebook we have two datasets available.  The first contains the wide area ocean shots containing the whales.  This dataset is located in data_336x224.  The second dataset is ~4500 crops of whale faces and an additional 4500 random crops from the same images.  This dataset is contained in data/train/faces and data/train/background respectively.  We are going to use this second dataset to train our classifier in DIGITS.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'question1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Question 1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">What might be a problem with using random crops from the images as our background set?</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Answer: <span class="cm-link">[Click here]</span><span class="cm-string">(#answer1)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-link">[Click here]</span><span class="cm-string">(/digits/)</span> to open DIGITS.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">First we need to import out dataset into DIGITS.  Use the Datasets-&gt;Images dropdown and select "classification" dataset.  The first time you'll be prompted to enter a Username.  Enter any standard username you like.  When the "New Image Classification Dataset" panel opens, use the following preoprocessing options:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![whale faces import]</span><span class="cm-string">(whale_faces_import.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">This will import the face/not-face dataset as color 256x256 images and split out 25% as a validation dataset - DIGITS will automagically know the names of the two classes from the image folder structure.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">It will take a couple of minutes to complete the import.  Once the import is complete, if you go back to the DIGITS main screen and then re-enter the whale_faces dataset, you can click the "Explore the db" button to see examples of the images in each class.  You should see something like this:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![whale face examples]</span><span class="cm-string">(whale_face_examples.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now we will train a simple two class CNN classifier on this dataset.  Return to the DIGITS main screen and use the Models-&gt;Images dropdown and select "classification" model.  On the "New Image Classification Model" panel that opens we will leave most options as default.  You just need to customize the following:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* Select the whale_faces dataset you just created </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* Choose the Standard Network "Alexnet"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* Set the number of training epochs to 5</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* Choose a name for the model, say "whale_faces_baseline"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The panel should look like this:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![DIGITS New Image Classification Model panel]</span><span class="cm-string">(whale_faces_digits_model.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now click "Create" to start training the model.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">You should see a live updating graph displaying the model training loss and the validation set loss and accuracy.  The losses should decrease as training progresses and the accuracy should increase.  It will take a few minutes for training to complete.  In the end you should see that the validation accuracy is around 98% - we have a pretty good whale face/non-face classifier!</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">You can test the classifier against an individual image patch by putting the URL <span class="cm-comment">`/home/ubuntu/data/whale/data/train/face/w_2606.jpg`</span> in to the Image URL text input and clicking "Classify One".  Be sure to check the box "Show visualizations and statistics" to see what the CNN is responding to in the image to make it's classification.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now that we have the model we are going to use it in this notebook to perform a sliding window detection of whale faces on a wide area aerial image.  The DIGITS job number for the model you just trained is found as the last part of the URL on that job's page, e.g. if the URL is <span class="cm-comment">`localhost/models/20160525-014512-ce40`</span> then the job number is <span class="cm-comment">`20160525-014512-ce40`</span>.  You need this number - we wil refer to the model job number as MODEL_JOB_NUM and to the dataset job number as DATASET_JOB_NUM in the following code.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Modify the code below with the correct MODEL_JOB_NUM for your model and DATASET_JOB_NUM for your dataset and then execute it.  It will take about 30 seconds to run.  The output will show a randomly chosen wide area test image along with an array showing the predicted class for each non-overlapping 256x256 grid square when input in to the model. </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 1135px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1150px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>Armed with this type of classifier we can then inspect each patch in a larger image, possibly using overlapping patches, and make a determination whether there is a whale present.  So let's do that.</p>
<p>For this notebook we have two datasets available.  The first contains the wide area ocean shots containing the whales.  This dataset is located in data_336x224.  The second dataset is ~4500 crops of whale faces and an additional 4500 random crops from the same images.  This dataset is contained in data/train/faces and data/train/background respectively.  We are going to use this second dataset to train our classifier in DIGITS.</p>
<p><a id="question1"></a></p>
<h3 id="Question-1">Question 1<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Question-1">¶</a></h3>
<p>What might be a problem with using random crops from the images as our background set?</p>
<p>Answer: <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#answer1">Click here</a></p>
<p><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/digits/" target="_blank">Click here</a> to open DIGITS.</p>
<p>First we need to import out dataset into DIGITS.  Use the Datasets-&gt;Images dropdown and select "classification" dataset.  The first time you'll be prompted to enter a Username.  Enter any standard username you like.  When the "New Image Classification Dataset" panel opens, use the following preoprocessing options:</p>
<p><img src="./Object detection_files/whale_faces_import.png" alt="whale faces import"></p>
<p>This will import the face/not-face dataset as color 256x256 images and split out 25% as a validation dataset - DIGITS will automagically know the names of the two classes from the image folder structure.  </p>
<p>It will take a couple of minutes to complete the import.  Once the import is complete, if you go back to the DIGITS main screen and then re-enter the whale_faces dataset, you can click the "Explore the db" button to see examples of the images in each class.  You should see something like this:</p>
<p><img src="./Object detection_files/whale_face_examples.png" alt="whale face examples"></p>
<p>Now we will train a simple two class CNN classifier on this dataset.  Return to the DIGITS main screen and use the Models-&gt;Images dropdown and select "classification" model.  On the "New Image Classification Model" panel that opens we will leave most options as default.  You just need to customize the following:</p>
<ul>
<li>Select the whale_faces dataset you just created </li>
<li>Choose the Standard Network "Alexnet"</li>
<li>Set the number of training epochs to 5</li>
<li>Choose a name for the model, say "whale_faces_baseline"</li>
</ul>
<p>The panel should look like this:</p>
<p><img src="./Object detection_files/whale_faces_digits_model.png" alt="DIGITS New Image Classification Model panel"></p>
<p>Now click "Create" to start training the model.</p>
<p>You should see a live updating graph displaying the model training loss and the validation set loss and accuracy.  The losses should decrease as training progresses and the accuracy should increase.  It will take a few minutes for training to complete.  In the end you should see that the validation accuracy is around 98% - we have a pretty good whale face/non-face classifier!</p>
<p>You can test the classifier against an individual image patch by putting the URL <code>/home/ubuntu/data/whale/data/train/face/w_2606.jpg</code> in to the Image URL text input and clicking "Classify One".  Be sure to check the box "Show visualizations and statistics" to see what the CNN is responding to in the image to make it's classification.</p>
<p>Now that we have the model we are going to use it in this notebook to perform a sliding window detection of whale faces on a wide area aerial image.  The DIGITS job number for the model you just trained is found as the last part of the URL on that job's page, e.g. if the URL is <code>localhost/models/20160525-014512-ce40</code> then the job number is <code>20160525-014512-ce40</code>.  You need this number - we wil refer to the model job number as MODEL_JOB_NUM and to the dataset job number as DATASET_JOB_NUM in the following code.</p>
<p>Modify the code below with the correct MODEL_JOB_NUM for your model and DATASET_JOB_NUM for your dataset and then execute it.  It will take about 30 seconds to run.  The output will show a randomly chosen wide area test image along with an array showing the predicted class for each non-overlapping 256x256 grid square when input in to the model. </p>
</div></div></div><div class="cell code_cell rendered selected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 549.594px; left: 89.5625px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 977px; margin-bottom: -15px; border-right-width: 15px; min-height: 1014px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 83.9688px; top: 544px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-operator">%</span><span class="cm-variable">matplotlib</span> <span class="cm-variable">inline</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">matplotlib</span>.<span class="cm-variable">pyplot</span> <span class="cm-keyword">as</span> <span class="cm-variable">plt</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">caffe</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">time</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">MODEL_JOB_NUM</span> = <span class="cm-string">'20160920-092148-8c17'</span>  <span class="cm-comment">## Remember to set this to be the job number for your model</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">DATASET_JOB_NUM</span> = <span class="cm-string">'20160920-090913-a43d'</span>  <span class="cm-comment">## Remember to set this to be the job number for your dataset</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">MODEL_FILE</span> = <span class="cm-string">'/home/ubuntu/digits/digits/jobs/'</span> <span class="cm-operator">+</span> <span class="cm-variable">MODEL_JOB_NUM</span> <span class="cm-operator">+</span> <span class="cm-string">'/deploy.prototxt'</span>                 <span class="cm-comment"># Do not change</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">PRETRAINED</span> = <span class="cm-string">'/home/ubuntu/digits/digits/jobs/'</span> <span class="cm-operator">+</span> <span class="cm-variable">MODEL_JOB_NUM</span> <span class="cm-operator">+</span> <span class="cm-string">'/snapshot_iter_270.caffemodel'</span>    <span class="cm-comment"># Do not change</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">MEAN_IMAGE</span> = <span class="cm-string">'/home/ubuntu/digits/digits/jobs/'</span> <span class="cm-operator">+</span> <span class="cm-variable">DATASET_JOB_NUM</span> <span class="cm-operator">+</span> <span class="cm-string">'/mean.jpg'</span>                      <span class="cm-comment"># Do not change</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># load the mean image</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">mean_image</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">io</span>.<span class="cm-variable">load_image</span>(<span class="cm-variable">MEAN_IMAGE</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Choose a random image to test against</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">RANDOM_IMAGE</span> = <span class="cm-builtin">str</span>(<span class="cm-variable">np</span>.<span class="cm-variable">random</span>.<span class="cm-variable">randint</span>(<span class="cm-number">10</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">IMAGE_FILE</span> = <span class="cm-string">'data/samples/w_'</span> <span class="cm-operator">+</span> <span class="cm-variable">RANDOM_IMAGE</span> <span class="cm-operator">+</span> <span class="cm-string">'.jpg'</span>                   </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Tell Caffe to use the GPU</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">caffe</span>.<span class="cm-variable">set_mode_gpu</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Initialize the Caffe model using the model trained in DIGITS</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">net</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">Classifier</span>(<span class="cm-variable">MODEL_FILE</span>, <span class="cm-variable">PRETRAINED</span>,</span></pre><pre class=""><span style="padding-right: 0.1px;">                       <span class="cm-variable">channel_swap</span>=(<span class="cm-number">2</span>,<span class="cm-number">1</span>,<span class="cm-number">0</span>),</span></pre><pre class=""><span style="padding-right: 0.1px;">                       <span class="cm-variable">raw_scale</span>=<span class="cm-number">255</span>,</span></pre><pre class=""><span style="padding-right: 0.1px;">                       <span class="cm-variable">image_dims</span>=(<span class="cm-number">256</span>, <span class="cm-number">256</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Load the input image into a numpy array and display it</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">input_image</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">io</span>.<span class="cm-variable">load_image</span>(<span class="cm-variable">IMAGE_FILE</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">input_image</span>)</span></pre><pre><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">show</span><span class=" CodeMirror-matchingbracket">(</span><span class=" CodeMirror-matchingbracket">)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Calculate how many 256x256 grid squares are in the image</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">rows</span> = <span class="cm-variable">input_image</span>.<span class="cm-variable">shape</span>[<span class="cm-number">0</span>]<span class="cm-operator">/</span><span class="cm-number">256</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">cols</span> = <span class="cm-variable">input_image</span>.<span class="cm-variable">shape</span>[<span class="cm-number">1</span>]<span class="cm-operator">/</span><span class="cm-number">256</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Initialize an empty array for the detections</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">detections</span> = <span class="cm-variable">np</span>.<span class="cm-variable">zeros</span>((<span class="cm-variable">rows</span>,<span class="cm-variable">cols</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Iterate over each grid square using the model to make a class prediction</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">start</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">rows</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">j</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">cols</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">grid_square</span> = <span class="cm-variable">input_image</span>[<span class="cm-variable">i</span><span class="cm-operator">*</span><span class="cm-number">256</span>:(<span class="cm-variable">i</span><span class="cm-operator">+</span><span class="cm-number">1</span>)<span class="cm-operator">*</span><span class="cm-number">256</span>,<span class="cm-variable">j</span><span class="cm-operator">*</span><span class="cm-number">256</span>:(<span class="cm-variable">j</span><span class="cm-operator">+</span><span class="cm-number">1</span>)<span class="cm-operator">*</span><span class="cm-number">256</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-comment"># subtract the mean image</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">grid_square</span> -= <span class="cm-variable">mean_image</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-comment"># make prediction</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">prediction</span> = <span class="cm-variable">net</span>.<span class="cm-variable">predict</span>([<span class="cm-variable">grid_square</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">detections</span>[<span class="cm-variable">i</span>,<span class="cm-variable">j</span>] = <span class="cm-variable">prediction</span>[<span class="cm-number">0</span>].<span class="cm-variable">argmax</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">end</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;">        </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display the predicted class for each grid square</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">detections</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display total time to perform inference</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">print</span> <span class="cm-string">'Total inference time: '</span> <span class="cm-operator">+</span> <span class="cm-builtin">str</span>(<span class="cm-variable">end</span><span class="cm-operator">-</span><span class="cm-variable">start</span>) <span class="cm-operator">+</span> <span class="cm-string">' seconds'</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 1014px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1029px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close" data-vivaldi-spatnav-clickable="1">×</button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" data-vivaldi-spatnav-clickable="1" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" data-vivaldi-spatnav-clickable="1" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 731px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 16.5px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;">As you run the above code multiple times you will see that in some cases this baseline model and sliding window approach is able to locate the whale's face - more often it will find a larger amount of the whale.  But you will also see the model is easily confused by breaking waves or sunlight reflecting from the ocean surface.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'question2'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Question 2</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">What are some ways we could improve the classification accuracy of this model?</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Answer: <span class="cm-link">[Click here]</span><span class="cm-string">(#answer2)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The fact that we used a sliding window with non-overlapping grid squares means that it is very likely that some of our grid squares will only partially contain a whale face and this can lead to misclassifications.  Unfortunately as we increase the overlap in the grid squares we will rapidly increase the computation time for this sliding window approach.  We also need to decide a method for combining overlapping classifications into a final classification "heatmap" - a popular approach for this is the non-maximal suppression (NMS) algorithm.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'question3'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Question 3</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">How could we counteract that increased computation time required for overlapping grid squares?</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Answer: <span class="cm-link">[Click here]</span><span class="cm-string">(#answer3)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Challenging optional exercises:</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'question-optional-exercise'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">1. Keeping the grid square size as 256x256, modify the code to increase the overlap between grid squares and obtain a finer classification map.</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">2. Modify the code to batch together multiple grid squares to pass in to the network for prediction.</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Answer: <span class="cm-link">[Click here]</span><span class="cm-string">(#answer-optional-exercise)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">As we have seen the advantage of this sliding window approach is that we can train a detector using only patch based training data (which is more widely available).  However there are several disadvantages:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* slow to make predictions, especially if there is large overlap between grid squares which leads to a great deal of redundant computation</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* challenging to produce a balanced training dataset that is robust to false alarm causing clutter</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* difficult to achieve scale invariance for object detection</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 731px;"></div><div class="CodeMirror-gutters" style="display: none; height: 746px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>As you run the above code multiple times you will see that in some cases this baseline model and sliding window approach is able to locate the whale's face - more often it will find a larger amount of the whale.  But you will also see the model is easily confused by breaking waves or sunlight reflecting from the ocean surface.</p>
<p><a id="question2"></a></p>
<h3 id="Question-2">Question 2<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Question-2">¶</a></h3>
<p>What are some ways we could improve the classification accuracy of this model?</p>
<p>Answer: <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#answer2">Click here</a></p>
<p>The fact that we used a sliding window with non-overlapping grid squares means that it is very likely that some of our grid squares will only partially contain a whale face and this can lead to misclassifications.  Unfortunately as we increase the overlap in the grid squares we will rapidly increase the computation time for this sliding window approach.  We also need to decide a method for combining overlapping classifications into a final classification "heatmap" - a popular approach for this is the non-maximal suppression (NMS) algorithm.</p>
<p><a id="question3"></a></p>
<h3 id="Question-3">Question 3<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Question-3">¶</a></h3>
<p>How could we counteract that increased computation time required for overlapping grid squares?</p>
<p>Answer: <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#answer3">Click here</a></p>
<h3 id="Challenging-optional-exercises:">Challenging optional exercises:<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Challenging-optional-exercises:">¶</a></h3>
<p><a id="question-optional-exercise"></a></p>
<ol>
<li><p>Keeping the grid square size as 256x256, modify the code to increase the overlap between grid squares and obtain a finer classification map.</p>
</li>
<li><p>Modify the code to batch together multiple grid squares to pass in to the network for prediction.</p>
</li>
</ol>
<p>Answer: <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#answer-optional-exercise">Click here</a></p>
<p>As we have seen the advantage of this sliding window approach is that we can train a detector using only patch based training data (which is more widely available).  However there are several disadvantages:</p>
<ul>
<li>slow to make predictions, especially if there is large overlap between grid squares which leads to a great deal of redundant computation</li>
<li>challenging to produce a balanced training dataset that is robust to false alarm causing clutter</li>
<li>difficult to achieve scale invariance for object detection</li>
</ul>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 490px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Object detection approach 2: candidate generation and classification</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">We will not actually demonstrate this second approach but we describe it here for completeness. Instead of using a classification CNN in a sliding window fashion you can instead use some computationally cheaper, sensitive, but false alarm prone algorithm to generate candidate detections.  Examples of algorithms used for this process are cascade classifiers and selective search.  These candidate detections are then passed to the CNN to be classified by object type or filtered out as background noise.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">These candidate generation algorithms will typically generate far fewer image patches to classify with the CNN than grid squares that need to be tested in a sliding window approach.  Furthermore, these candidate detections can be batched together before input into the CNN to benefit from parallelism.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Fig 3 shows how this approach would be used in a vehicle detection scenario.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![candidate generation example]</span><span class="cm-string">(candidate_generation_example.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">h4</span> <span class="cm-attribute">align</span>=<span class="cm-string">"center"</span><span class="cm-tag cm-bracket">&gt;</span>Figure 3: CNN classifier with candidate generation pre-processing<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">h4</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The benefits of this approach are:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* the speedup due to a smaller number of candidate detections to test</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* depending on the candidate generation algorithm we may get more accurate localization of the object</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The drawbacks of this approach are:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* a more complex multi-stage processing pipeline</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* an additional model to build or train for candidate generation</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* a non-trivial false alarm rate</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* variable inference time dependent on the number of candidates generated</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 490px;"></div><div class="CodeMirror-gutters" style="display: none; height: 505px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Object-detection-approach-2:-candidate-generation-and-classification">Object detection approach 2: candidate generation and classification<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Object-detection-approach-2:-candidate-generation-and-classification">¶</a></h2>
<p>We will not actually demonstrate this second approach but we describe it here for completeness. Instead of using a classification CNN in a sliding window fashion you can instead use some computationally cheaper, sensitive, but false alarm prone algorithm to generate candidate detections.  Examples of algorithms used for this process are cascade classifiers and selective search.  These candidate detections are then passed to the CNN to be classified by object type or filtered out as background noise.</p>
<p>These candidate generation algorithms will typically generate far fewer image patches to classify with the CNN than grid squares that need to be tested in a sliding window approach.  Furthermore, these candidate detections can be batched together before input into the CNN to benefit from parallelism.</p>
<p>Fig 3 shows how this approach would be used in a vehicle detection scenario.</p>
<p><img src="./Object detection_files/candidate_generation_example.png" alt="candidate generation example"></p>
<h4 align="center" id="Figure-3:-CNN-classifier-with-candidate-generation-pre-processing">Figure 3: CNN classifier with candidate generation pre-processing<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Figure-3:-CNN-classifier-with-candidate-generation-pre-processing">¶</a></h4> 

<p>The benefits of this approach are:</p>
<ul>
<li>the speedup due to a smaller number of candidate detections to test</li>
<li>depending on the candidate generation algorithm we may get more accurate localization of the object</li>
</ul>
<p>The drawbacks of this approach are:</p>
<ul>
<li>a more complex multi-stage processing pipeline</li>
<li>an additional model to build or train for candidate generation</li>
<li>a non-trivial false alarm rate</li>
<li>variable inference time dependent on the number of candidates generated</li>
</ul>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 849px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Object detection approach 3: fully-convolutional network (FCN)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">As mentioned earlier there is a great deal of redundant computation in the sliding window approach with overlapping windows.  Thankfully there is neat trick to avoid this redundancy.  The commonly used fully-connected layers towards the classification end of a CNN like Alexnet can be trivially replaced with convolutional layers.  These replacement layers have convolutional filters that are the same size as the feature map outputs for the previous layer and the number of filters is equal to the number of neurons in the fully-connected layer it replaces.  The benefit of making this replacement is that images of varying size can be input in to the network for classification.  If the input image is smaller than the expected image size for the network (called the receptive field of the network) then we will still just obtain a single classification for the image. However, if the image is larger than the receptive field then we will obtain a heatmap of classifications, much like we obtained from the sliding window approach.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Let's see how that works for AlexNet's <span class="cm-comment">`fc6`</span> layer.</span></pre><pre class=""><span style="padding-right: 0.1px;">You can use DIGITS to inspect the shape of the input to <span class="cm-comment">`fc6`</span>: using the CNN classifier that you just trained in the first part of this lab, check the box "Show visualizations and statistics" and test any arbitrary image.</span></pre><pre class=""><span style="padding-right: 0.1px;">You will see something like Figure 4 below:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![alexnet layers]</span><span class="cm-string">(alexnet_layers.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">h4</span> <span class="cm-attribute">align</span>=<span class="cm-string">"center"</span><span class="cm-tag cm-bracket">&gt;</span>Figure 4: Alexnet FC6 layer<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">h4</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">There you can see that <span class="cm-comment">`fc6`</span> receives its input from <span class="cm-comment">`pool5`</span>.</span></pre><pre class=""><span style="padding-right: 0.1px;">The shape of the activations at <span class="cm-comment">`pool5`</span> is <span class="cm-comment">`256*6*6`</span>.</span></pre><pre class=""><span style="padding-right: 0.1px;">The shape of the activations at <span class="cm-comment">`fc6`</span> is <span class="cm-comment">`4096`</span>, meaning that <span class="cm-comment">`fc6`</span> has <span class="cm-comment">`4096`</span> output neurons.</span></pre><pre class=""><span style="padding-right: 0.1px;">To turn <span class="cm-comment">`fc6`</span> into an equivalent convolutional layer, we would need to create a convolutional layer with <span class="cm-comment">`6*6`</span> kernel size and <span class="cm-comment">`4096`</span> output feature maps.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Let's try this out with our whale detection problem.  Go back to DIGITS and clone your baseline whale face detection model using the "Clone" button in the top right corner of the model screen.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now choose the "Customize" option alongside your selection of the Alexnet network architecture.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'exercise1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Exercise:</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Replace the fully-connected (InnerProduct) layer <span class="cm-comment">`fc6`</span> with a convolutional layer with a convolutional layer with 256 6x6 convolutional filters and zero padding. Similarly, replace <span class="cm-comment">`fc7`</span> and <span class="cm-comment">`fc8`</span> with equivalent convolutional layers.</span></pre><pre class=""><span style="padding-right: 0.1px;">See if you can successfully train this model.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Answer: <span class="cm-link">[click here]</span><span class="cm-string">(#answer4)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Once you have made the required the changes the model should train and achieve approximately the same validation accuracy of ~98%.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now we can use this model to directly compute the classification heatmap for an entire large aerial image.  Effectively we are still performing a sliding window classification but all of the sliding window process is efficiently handled within the FCN.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Run the code below to see this in action.  Again you will need to obtain your models job number and replace it in the code.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 849px;"></div><div class="CodeMirror-gutters" style="display: none; height: 864px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Object-detection-approach-3:-fully-convolutional-network-(FCN)">Object detection approach 3: fully-convolutional network (FCN)<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Object-detection-approach-3:-fully-convolutional-network-(FCN)">¶</a></h2>
<p>As mentioned earlier there is a great deal of redundant computation in the sliding window approach with overlapping windows.  Thankfully there is neat trick to avoid this redundancy.  The commonly used fully-connected layers towards the classification end of a CNN like Alexnet can be trivially replaced with convolutional layers.  These replacement layers have convolutional filters that are the same size as the feature map outputs for the previous layer and the number of filters is equal to the number of neurons in the fully-connected layer it replaces.  The benefit of making this replacement is that images of varying size can be input in to the network for classification.  If the input image is smaller than the expected image size for the network (called the receptive field of the network) then we will still just obtain a single classification for the image. However, if the image is larger than the receptive field then we will obtain a heatmap of classifications, much like we obtained from the sliding window approach.</p>
<p>Let's see how that works for AlexNet's <code>fc6</code> layer.
You can use DIGITS to inspect the shape of the input to <code>fc6</code>: using the CNN classifier that you just trained in the first part of this lab, check the box "Show visualizations and statistics" and test any arbitrary image.
You will see something like Figure 4 below:</p>
<p><img src="./Object detection_files/alexnet_layers.png" alt="alexnet layers"></p>
<h4 align="center" id="Figure-4:-Alexnet-FC6-layer">Figure 4: Alexnet FC6 layer<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Figure-4:-Alexnet-FC6-layer">¶</a></h4>

<p>There you can see that <code>fc6</code> receives its input from <code>pool5</code>.
The shape of the activations at <code>pool5</code> is <code>256*6*6</code>.
The shape of the activations at <code>fc6</code> is <code>4096</code>, meaning that <code>fc6</code> has <code>4096</code> output neurons.
To turn <code>fc6</code> into an equivalent convolutional layer, we would need to create a convolutional layer with <code>6*6</code> kernel size and <code>4096</code> output feature maps.</p>
<p>Let's try this out with our whale detection problem.  Go back to DIGITS and clone your baseline whale face detection model using the "Clone" button in the top right corner of the model screen.</p>
<p>Now choose the "Customize" option alongside your selection of the Alexnet network architecture.</p>
<p><a id="exercise1"></a></p>
<h3 id="Exercise:">Exercise:<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Exercise:">¶</a></h3>
<p>Replace the fully-connected (InnerProduct) layer <code>fc6</code> with a convolutional layer with a convolutional layer with 256 6x6 convolutional filters and zero padding. Similarly, replace <code>fc7</code> and <code>fc8</code> with equivalent convolutional layers.
See if you can successfully train this model.</p>
<p>Answer: <a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#answer4">click here</a></p>
<p>Once you have made the required the changes the model should train and achieve approximately the same validation accuracy of ~98%.</p>
<p>Now we can use this model to directly compute the classification heatmap for an entire large aerial image.  Effectively we are still performing a sliding window classification but all of the sliding window process is efficiently handled within the FCN.</p>
<p>Run the code below to see this in action.  Again you will need to obtain your models job number and replace it in the code.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 927px; margin-bottom: -15px; border-right-width: 15px; min-height: 963px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-operator">%</span><span class="cm-variable">matplotlib</span> <span class="cm-variable">inline</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">matplotlib</span>.<span class="cm-variable">pyplot</span> <span class="cm-keyword">as</span> <span class="cm-variable">plt</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">caffe</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">copy</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">scipy</span>.<span class="cm-variable">misc</span> <span class="cm-keyword">import</span> <span class="cm-variable">imresize</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">time</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">JOB_NUM</span> = <span class="cm-string">'20160920-110807-298d'</span>  <span class="cm-comment">## Remember to set this to be the job number for your model</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">MODEL_FILE</span> = <span class="cm-string">'/home/ubuntu/digits/digits/jobs/'</span> <span class="cm-operator">+</span> <span class="cm-variable">JOB_NUM</span> <span class="cm-operator">+</span> <span class="cm-string">'/deploy.prototxt'</span>                 <span class="cm-comment"># Do not change</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">PRETRAINED</span> = <span class="cm-string">'/home/ubuntu/digits/digits/jobs/'</span> <span class="cm-operator">+</span> <span class="cm-variable">JOB_NUM</span> <span class="cm-operator">+</span> <span class="cm-string">'/snapshot_iter_270.caffemodel'</span>    <span class="cm-comment"># Do not change</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Choose a random image to test against</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">RANDOM_IMAGE</span> = <span class="cm-builtin">str</span>(<span class="cm-variable">np</span>.<span class="cm-variable">random</span>.<span class="cm-variable">randint</span>(<span class="cm-number">10</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">IMAGE_FILE</span> = <span class="cm-string">'data/samples/w_'</span> <span class="cm-operator">+</span> <span class="cm-variable">RANDOM_IMAGE</span> <span class="cm-operator">+</span> <span class="cm-string">'.jpg'</span>                  </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Tell Caffe to use the GPU</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">caffe</span>.<span class="cm-variable">set_mode_gpu</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Load the input image into a numpy array and display it</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">input_image</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">io</span>.<span class="cm-variable">load_image</span>(<span class="cm-variable">IMAGE_FILE</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">input_image</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">show</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Initialize the Caffe model using the model trained in DIGITS</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># This time the model input size is reshaped based on the randomly selected input image</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">net</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">Net</span>(<span class="cm-variable">MODEL_FILE</span>,<span class="cm-variable">PRETRAINED</span>,<span class="cm-variable">caffe</span>.<span class="cm-variable">TEST</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">net</span>.<span class="cm-variable">blobs</span>[<span class="cm-string">'data'</span>].<span class="cm-variable">reshape</span>(<span class="cm-number">1</span>, <span class="cm-number">3</span>, <span class="cm-variable">input_image</span>.<span class="cm-variable">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">input_image</span>.<span class="cm-variable">shape</span>[<span class="cm-number">1</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">net</span>.<span class="cm-variable">reshape</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">transformer</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">io</span>.<span class="cm-variable">Transformer</span>({<span class="cm-string">'data'</span>: <span class="cm-variable">net</span>.<span class="cm-variable">blobs</span>[<span class="cm-string">'data'</span>].<span class="cm-variable">data</span>.<span class="cm-variable">shape</span>})</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">transformer</span>.<span class="cm-variable">set_transpose</span>(<span class="cm-string">'data'</span>, (<span class="cm-number">2</span>,<span class="cm-number">0</span>,<span class="cm-number">1</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">transformer</span>.<span class="cm-variable">set_channel_swap</span>(<span class="cm-string">'data'</span>, (<span class="cm-number">2</span>,<span class="cm-number">1</span>,<span class="cm-number">0</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">transformer</span>.<span class="cm-variable">set_raw_scale</span>(<span class="cm-string">'data'</span>, <span class="cm-number">255.0</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># This is just a colormap for displaying the results</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">my_cmap</span> = <span class="cm-variable">copy</span>.<span class="cm-variable">copy</span>(<span class="cm-variable">plt</span>.<span class="cm-variable">cm</span>.<span class="cm-variable">get_cmap</span>(<span class="cm-string">'jet'</span>)) <span class="cm-comment"># get a copy of the jet color map</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">my_cmap</span>.<span class="cm-variable">set_bad</span>(<span class="cm-variable">alpha</span>=<span class="cm-number">0</span>) <span class="cm-comment"># set how the colormap handles 'bad' values</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Feed the whole input image into the model for classification</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">start</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">out</span> = <span class="cm-variable">net</span>.<span class="cm-variable">forward</span>(<span class="cm-variable">data</span>=<span class="cm-variable">np</span>.<span class="cm-variable">asarray</span>([<span class="cm-variable">transformer</span>.<span class="cm-variable">preprocess</span>(<span class="cm-string">'data'</span>, <span class="cm-variable">input_image</span>)]))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">end</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Create an overlay visualization of the classification result</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">im</span> = <span class="cm-variable">transformer</span>.<span class="cm-variable">deprocess</span>(<span class="cm-string">'data'</span>, <span class="cm-variable">net</span>.<span class="cm-variable">blobs</span>[<span class="cm-string">'data'</span>].<span class="cm-variable">data</span>[<span class="cm-number">0</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">classifications</span> = <span class="cm-variable">out</span>[<span class="cm-string">'softmax'</span>][<span class="cm-number">0</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">classifications</span> = <span class="cm-variable">imresize</span>(<span class="cm-variable">classifications</span>.<span class="cm-variable">argmax</span>(<span class="cm-variable">axis</span>=<span class="cm-number">0</span>),<span class="cm-variable">input_image</span>.<span class="cm-variable">shape</span>,<span class="cm-variable">interp</span>=<span class="cm-string">'bilinear'</span>).<span class="cm-variable">astype</span>(<span class="cm-string">'float'</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">classifications</span>[<span class="cm-variable">classifications</span><span class="cm-operator">==</span><span class="cm-number">0</span>] = <span class="cm-variable">np</span>.<span class="cm-variable">nan</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">im</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">classifications</span>,<span class="cm-variable">alpha</span>=<span class="cm-number">.5</span>,<span class="cm-variable">cmap</span>=<span class="cm-variable">my_cmap</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">show</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display total time to perform inference</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">print</span> <span class="cm-string">'Total inference time: '</span> <span class="cm-operator">+</span> <span class="cm-builtin">str</span>(<span class="cm-variable">end</span><span class="cm-operator">-</span><span class="cm-variable">start</span>) <span class="cm-operator">+</span> <span class="cm-string">' seconds'</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 963px;"></div><div class="CodeMirror-gutters" style="display: none; height: 978px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close" data-vivaldi-spatnav-clickable="1">×</button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" data-vivaldi-spatnav-clickable="1" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" data-vivaldi-spatnav-clickable="1" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 368px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 16.5px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;">As you run the above code multiple times you will see that in many cases the FCN is able to locate the whale's face with greater precision than the sliding window approach. Often it will still find a larger amount of the whale and is sometimes confused by breaking waves or sunlight reflecting from the ocean surface. Again, the false alarms caused by background clutter and the whale's body could be mitigated using appropriate data augmentation.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Note that the total inference time for the FCN is about 1.5 seconds, wheras for the sliding window approach it took 10 seconds.  So we get a better quality result in a fraction of the time!  This is a great benefit if we wish to deploy our detector in a real-time application, e.g. on board an aircraft, as we obtain a single model that can perform detection and classification in one efficient pass.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In addition to data augmentation for our training data there are a couple of common ways to improve the classification accuracy and localization precision of an FCN approach.  The most common of these is to pass the input image through the network multiple times at varying scales.  This improves the models tolerance to scale variation in the appearance of the object of interest.  We can also modify the network layer strides to provide finer or coarser grained classification heatmap outputs.  By using multiple versions of the input image and classification network simultaneously and then performing a classification heatmap merging procedure we can improve the final classification and detection result drastically.  A well known example of this approach was presented in the paper OverFeat (Figure 5).</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![overfeat]</span><span class="cm-string">(overfeat.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">h4</span> <span class="cm-attribute">align</span>=<span class="cm-string">"center"</span><span class="cm-tag cm-bracket">&gt;</span>Figure 5: OverFeat method for improving detection resolution<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">h4</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 368px;"></div><div class="CodeMirror-gutters" style="display: none; height: 383px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>As you run the above code multiple times you will see that in many cases the FCN is able to locate the whale's face with greater precision than the sliding window approach. Often it will still find a larger amount of the whale and is sometimes confused by breaking waves or sunlight reflecting from the ocean surface. Again, the false alarms caused by background clutter and the whale's body could be mitigated using appropriate data augmentation.</p>
<p>Note that the total inference time for the FCN is about 1.5 seconds, wheras for the sliding window approach it took 10 seconds.  So we get a better quality result in a fraction of the time!  This is a great benefit if we wish to deploy our detector in a real-time application, e.g. on board an aircraft, as we obtain a single model that can perform detection and classification in one efficient pass.</p>
<p>In addition to data augmentation for our training data there are a couple of common ways to improve the classification accuracy and localization precision of an FCN approach.  The most common of these is to pass the input image through the network multiple times at varying scales.  This improves the models tolerance to scale variation in the appearance of the object of interest.  We can also modify the network layer strides to provide finer or coarser grained classification heatmap outputs.  By using multiple versions of the input image and classification network simultaneously and then performing a classification heatmap merging procedure we can improve the final classification and detection result drastically.  A well known example of this approach was presented in the paper OverFeat (Figure 5).</p>
<p><img src="./Object detection_files/overfeat.png" alt="overfeat"></p>
<h4 align="center" id="Figure-5:-OverFeat-method-for-improving-detection-resolution">Figure 5: OverFeat method for improving detection resolution<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Figure-5:-OverFeat-method-for-improving-detection-resolution">¶</a></h4> </div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 98px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 19px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Exercise:</span><span class="cm-header cm-header-3 cm-trailing-space-a"> </span><span class="cm-header cm-header-3 cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now go back and modify the FCN test code to see the effect of passing different sized input images in to the network.  First, choose a fixed input image to test against.  Then manually resize that image before passing it in to the network.  Do this a few times and compare the effect on detection accuracy.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 98px;"></div><div class="CodeMirror-gutters" style="display: none; height: 113px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Exercise:">Exercise:<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Exercise:">¶</a></h3>
<p>Now go back and modify the FCN test code to see the effect of passing different sized input images in to the network.  First, choose a fixed input image to test against.  Then manually resize that image before passing it in to the network.  Do this a few times and compare the effect on detection accuracy.</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 1391px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Object detection approach 4: DetectNet</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">There is a final class of object approaches that train a CNN to simultaneously classify the most likely object present at each location within an image and predict the corresponding bounding box for that object through regression.  For example:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![yolo]</span><span class="cm-string">(yolo.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">This approach has major benefits:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* Simple one-shot detection, classification and bounding box regression pipeline</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* Very low latency</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* Very low false alarm rates due to strong, voluminous background training data</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In order to train this type of network specialized training data is required where all objects of interest are labelled with accurate bounding boxes.  This type of training data is much rarer and costly to produce; however, if this type of data is available for your object detection problem this is almost certainly the best approach to take. Fig 5 shows an example of a labelled training sample for a vehicle detection scenario.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![kespry example]</span><span class="cm-string">(kespry_example.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">h4</span> <span class="cm-attribute">align</span>=<span class="cm-string">"center"</span><span class="cm-tag cm-bracket">&gt;</span>Figure 6: Labelled data for a three class object detection scenario<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">h4</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The recent release of DIGITS 4 added the capability to train this class of model and provided a new "standard network" called DetectNet as an example.  We are going to use DetectNet to train a Right Whale detector in full-size aerial images of the ocean.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The main challenge in training a single CNN for object detection and bounding box regression is in handling the fact that there can be varying numbers of objects present in different images.  In some cases you may even have an image with no objects at all.  DetectNet handles this problem by converting an image with an number of bounding box annotations to a fixed dimensionality data representation that we directly attempt to predict with a CNN.  Fig 6 shows how data is mapped to this represenation for a single class object detection problem.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![detectnet data rep]</span><span class="cm-string">(detectnet_data.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">h4</span> <span class="cm-attribute">align</span>=<span class="cm-string">"center"</span><span class="cm-tag cm-bracket">&gt;</span>Figure 7: DetectNet data representation<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">h4</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">DetectNet is actually an FCN, as we described above, but configured to produce precisely this data representation as it's output.  The bulk of the layers in DetectNet are identical to the well known GoogLeNet network.  Fig 7 shows the DetectNet architecture for training.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![detectnet training architecture]</span><span class="cm-string">(detectnet_training.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">h4</span> <span class="cm-attribute">align</span>=<span class="cm-string">"center"</span><span class="cm-tag cm-bracket">&gt;</span>Figure 8: DetectNet training architecture<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">h4</span><span class="cm-tag cm-bracket">&gt;</span> </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">For the purposes of this lab we have already prepared the full-size aerial images of the ocean in the appropriate folders and format for training DetectNet.  We first need to import this data into DIGITS.  Use the Datasets-&gt;Images dropdown and select "object detection" dataset. When the "New Object Detection Dataset" panel opens, use the following preoprocessing options:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![OD data ingest]</span><span class="cm-string">(OD_ingest.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now we will first look at how to train DetectNet on this dataset. A complete training run of DetectNet on this dataset takes several hours, so we have provided a trained model to experiment with.  Return to the main DIGITS screen and use the Models tab.  Open the "whale_detectnet" model and clone it.  Make the following changes:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* select your newly created "whales_detectnet" dataset</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* change the number of training epochs to 3</span><span class="cm-variable-2 cm-trailing-space-a"> </span><span class="cm-variable-2 cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">* change the batch size to 10</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Feel free to explore the network architecture visually by clicking the "Visualize" button.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">When you're ready to train, give the model a new name like "whale_detectnet_2" and click "create".  Training this model for just 3 epochs will still take about 8 minutes, but you should see both the coverage and bounding box training and validation loss values decreasing already.  You will also see the mean Average Precision (mAP) score begin to rise.  mAP is a combined measure of how well the network is able to detect the whale faces and how accurate it's bounding box estimates were for the validation dataset.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Once the model has finished training return to the pre-trained "whale_detectnet" model.  You will see that after 100 training epochs this model had not only converged to low training and validation loss values, but also a high mAP score.  Let's test this trained model against a validation image to see if it can find the whale face.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Simply set the visualization method to "Bounding boxes" and paste the following image path in:  <span class="cm-comment">`/home/ubuntu/data/whale/data_336x224/val/images/000000118.png`</span>.  Be sure to select the "Show visualizations and statistics" checkbox and then click "Test One".  You should see DetectNet successfully detects the whale face and draws a bounding box, like this:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![detectnet success]</span><span class="cm-string">(detectnet_success.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Feel free to test other images from the <span class="cm-comment">`/home/ubuntu/data/whale/data_336x224/val/images/`</span> folder.  You will see that DetectNet is able to accurately detect most whale faces with a tightly drawn bounding box and has a very low false alarm rate.  Furthermore, inference is extremely fast with DetectNet.  Execute the following cell to use the Caffe command line interface to carry out an inference benchmark using the DetectNet architecture.  You should see that the average time taken to pass a single 336x224 pixel image forward through DetectNet is just 22ms.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 1391px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1406px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Object-detection-approach-4:-DetectNet">Object detection approach 4: DetectNet<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Object-detection-approach-4:-DetectNet">¶</a></h2>
<p>There is a final class of object approaches that train a CNN to simultaneously classify the most likely object present at each location within an image and predict the corresponding bounding box for that object through regression.  For example:</p>
<p><img src="./Object detection_files/yolo.png" alt="yolo"></p>
<p>This approach has major benefits:</p>
<ul>
<li>Simple one-shot detection, classification and bounding box regression pipeline</li>
<li>Very low latency</li>
<li>Very low false alarm rates due to strong, voluminous background training data</li>
</ul>
<p>In order to train this type of network specialized training data is required where all objects of interest are labelled with accurate bounding boxes.  This type of training data is much rarer and costly to produce; however, if this type of data is available for your object detection problem this is almost certainly the best approach to take. Fig 5 shows an example of a labelled training sample for a vehicle detection scenario.</p>
<p><img src="./Object detection_files/kespry_example.png" alt="kespry example"></p>
<h4 align="center" id="Figure-6:-Labelled-data-for-a-three-class-object-detection-scenario">Figure 6: Labelled data for a three class object detection scenario<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Figure-6:-Labelled-data-for-a-three-class-object-detection-scenario">¶</a></h4> 

<p>The recent release of DIGITS 4 added the capability to train this class of model and provided a new "standard network" called DetectNet as an example.  We are going to use DetectNet to train a Right Whale detector in full-size aerial images of the ocean.  </p>
<p>The main challenge in training a single CNN for object detection and bounding box regression is in handling the fact that there can be varying numbers of objects present in different images.  In some cases you may even have an image with no objects at all.  DetectNet handles this problem by converting an image with an number of bounding box annotations to a fixed dimensionality data representation that we directly attempt to predict with a CNN.  Fig 6 shows how data is mapped to this represenation for a single class object detection problem.</p>
<p><img src="./Object detection_files/detectnet_data.png" alt="detectnet data rep"></p>
<h4 align="center" id="Figure-7:-DetectNet-data-representation">Figure 7: DetectNet data representation<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Figure-7:-DetectNet-data-representation">¶</a></h4> 

<p>DetectNet is actually an FCN, as we described above, but configured to produce precisely this data representation as it's output.  The bulk of the layers in DetectNet are identical to the well known GoogLeNet network.  Fig 7 shows the DetectNet architecture for training.</p>
<p><img src="./Object detection_files/detectnet_training.png" alt="detectnet training architecture"></p>
<h4 align="center" id="Figure-8:-DetectNet-training-architecture">Figure 8: DetectNet training architecture<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Figure-8:-DetectNet-training-architecture">¶</a></h4> 

<p>For the purposes of this lab we have already prepared the full-size aerial images of the ocean in the appropriate folders and format for training DetectNet.  We first need to import this data into DIGITS.  Use the Datasets-&gt;Images dropdown and select "object detection" dataset. When the "New Object Detection Dataset" panel opens, use the following preoprocessing options:</p>
<p><img src="./Object detection_files/OD_ingest.png" alt="OD data ingest"></p>
<p>Now we will first look at how to train DetectNet on this dataset. A complete training run of DetectNet on this dataset takes several hours, so we have provided a trained model to experiment with.  Return to the main DIGITS screen and use the Models tab.  Open the "whale_detectnet" model and clone it.  Make the following changes:</p>
<ul>
<li>select your newly created "whales_detectnet" dataset</li>
<li>change the number of training epochs to 3  </li>
<li>change the batch size to 10</li>
</ul>
<p>Feel free to explore the network architecture visually by clicking the "Visualize" button.  </p>
<p>When you're ready to train, give the model a new name like "whale_detectnet_2" and click "create".  Training this model for just 3 epochs will still take about 8 minutes, but you should see both the coverage and bounding box training and validation loss values decreasing already.  You will also see the mean Average Precision (mAP) score begin to rise.  mAP is a combined measure of how well the network is able to detect the whale faces and how accurate it's bounding box estimates were for the validation dataset.</p>
<p>Once the model has finished training return to the pre-trained "whale_detectnet" model.  You will see that after 100 training epochs this model had not only converged to low training and validation loss values, but also a high mAP score.  Let's test this trained model against a validation image to see if it can find the whale face.</p>
<p>Simply set the visualization method to "Bounding boxes" and paste the following image path in:  <code>/home/ubuntu/data/whale/data_336x224/val/images/000000118.png</code>.  Be sure to select the "Show visualizations and statistics" checkbox and then click "Test One".  You should see DetectNet successfully detects the whale face and draws a bounding box, like this:</p>
<p><img src="./Object detection_files/detectnet_success.png" alt="detectnet success"></p>
<p>Feel free to test other images from the <code>/home/ubuntu/data/whale/data_336x224/val/images/</code> folder.  You will see that DetectNet is able to accurately detect most whale faces with a tightly drawn bounding box and has a very low false alarm rate.  Furthermore, inference is extremely fast with DetectNet.  Execute the following cell to use the Caffe command line interface to carry out an inference benchmark using the DetectNet architecture.  You should see that the average time taken to pass a single 336x224 pixel image forward through DetectNet is just 22ms.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 565.672px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre><span style="padding-right: 0.1px;"><span class="cm-operator">!</span><span class="cm-variable">caffe</span> <span class="cm-variable">time</span> <span class="cm-operator">--</span><span class="cm-variable">model</span> <span class="cm-operator">/</span><span class="cm-variable">home</span><span class="cm-operator">/</span><span class="cm-variable">ubuntu</span><span class="cm-operator">/</span><span class="cm-variable">data</span><span class="cm-operator">/</span><span class="cm-variable">whale</span><span class="cm-operator">/</span><span class="cm-variable">deploy</span>.<span class="cm-variable">prototxt</span> <span class="cm-operator">--</span><span class="cm-variable">gpu</span> <span class="cm-number">0</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close" data-vivaldi-spatnav-clickable="1">×</button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" data-vivaldi-spatnav-clickable="1" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" data-vivaldi-spatnav-clickable="1" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 583px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Answers to questions:</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'answer1'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Answer 1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Random patches may end up containing whale faces too.  This is unlikely as the faces are typically only a very small part of the image and we have a large sample of random background patches which will almost entirely not contain whale faces.  We may also get whale bodies and tails in our background set, but this good as we are interested in localizing whale faces.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-link">[Click here]</span><span class="cm-string">(#question1)</span> to return to question 1</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'answer2'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Answer 2</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Some good things to try would be to use a larger number of randomly selected non-face patches and to balance the dataset by augmenting the existing face patches with random rotations, flips and scalings.  You could also train a model with a larger number of trainable parameters such as GoogleNet.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-link">[Click here]</span><span class="cm-string">(#question2)</span> to return to question 2</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'answer3'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Answer 3</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">We could batch together multiple grid squares at a time to feed into the network for classification as a batch - that way we can further exploit parallelism and get computational acceleration from the GPU.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-link">[Click here]</span><span class="cm-string">(#question3)</span> to return to question 3</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'answer-optional-exercise'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Answer to optional exercise</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 583px;"></div><div class="CodeMirror-gutters" style="display: none; height: 598px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Answers-to-questions:">Answers to questions:<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Answers-to-questions:">¶</a></h2>
<p><a id="answer1"></a></p>
<h3 id="Answer-1">Answer 1<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Answer-1">¶</a></h3>
<p>Random patches may end up containing whale faces too.  This is unlikely as the faces are typically only a very small part of the image and we have a large sample of random background patches which will almost entirely not contain whale faces.  We may also get whale bodies and tails in our background set, but this good as we are interested in localizing whale faces.</p>
<p><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#question1">Click here</a> to return to question 1</p>
<p><a id="answer2"></a></p>
<h3 id="Answer-2">Answer 2<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Answer-2">¶</a></h3>
<p>Some good things to try would be to use a larger number of randomly selected non-face patches and to balance the dataset by augmenting the existing face patches with random rotations, flips and scalings.  You could also train a model with a larger number of trainable parameters such as GoogleNet.</p>
<p><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#question2">Click here</a> to return to question 2</p>
<p><a id="answer3"></a></p>
<h3 id="Answer-3">Answer 3<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Answer-3">¶</a></h3>
<p>We could batch together multiple grid squares at a time to feed into the network for classification as a batch - that way we can further exploit parallelism and get computational acceleration from the GPU.</p>
<p><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#question3">Click here</a> to return to question 3</p>
<p><a id="answer-optional-exercise"></a></p>
<h3 id="Answer-to-optional-exercise">Answer to optional exercise<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Answer-to-optional-exercise">¶</a></h3>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 977px; margin-bottom: -15px; border-right-width: 15px; min-height: 2170px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-operator">%</span><span class="cm-variable">matplotlib</span> <span class="cm-variable">inline</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">matplotlib</span>.<span class="cm-variable">pyplot</span> <span class="cm-keyword">as</span> <span class="cm-variable">plt</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">caffe</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">time</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">MODEL_JOB_NUM</span> = <span class="cm-string">'20160920-092148-8c17'</span>  <span class="cm-comment">## Remember to set this to be the job number for your model</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">DATASET_JOB_NUM</span> = <span class="cm-string">'20160920-090913-a43d'</span>  <span class="cm-comment">## Remember to set this to be the job number for your dataset</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">MODEL_FILE</span> = <span class="cm-string">'/home/ubuntu/digits/digits/jobs/'</span> <span class="cm-operator">+</span> <span class="cm-variable">MODEL_JOB_NUM</span> <span class="cm-operator">+</span> <span class="cm-string">'/deploy.prototxt'</span>                 <span class="cm-comment"># Do not change</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">PRETRAINED</span> = <span class="cm-string">'/home/ubuntu/digits/digits/jobs/'</span> <span class="cm-operator">+</span> <span class="cm-variable">MODEL_JOB_NUM</span> <span class="cm-operator">+</span> <span class="cm-string">'/snapshot_iter_270.caffemodel'</span>    <span class="cm-comment"># Do not change</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">MEAN_IMAGE</span> = <span class="cm-string">'/home/ubuntu/digits/digits/jobs/'</span> <span class="cm-operator">+</span> <span class="cm-variable">DATASET_JOB_NUM</span> <span class="cm-operator">+</span> <span class="cm-string">'/mean.jpg'</span>                      <span class="cm-comment"># Do not change</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># load the mean image</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">mean_image</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">io</span>.<span class="cm-variable">load_image</span>(<span class="cm-variable">MEAN_IMAGE</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Choose a random image to test against</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">RANDOM_IMAGE</span> = <span class="cm-builtin">str</span>(<span class="cm-variable">np</span>.<span class="cm-variable">random</span>.<span class="cm-variable">randint</span>(<span class="cm-number">10</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">IMAGE_FILE</span> = <span class="cm-string">'data/samples/w_'</span> <span class="cm-operator">+</span> <span class="cm-variable">RANDOM_IMAGE</span> <span class="cm-operator">+</span> <span class="cm-string">'.jpg'</span> </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Tell Caffe to use the GPU</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">caffe</span>.<span class="cm-variable">set_mode_gpu</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Initialize the Caffe model using the model trained in DIGITS</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">net</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">Classifier</span>(<span class="cm-variable">MODEL_FILE</span>, <span class="cm-variable">PRETRAINED</span>,</span></pre><pre class=""><span style="padding-right: 0.1px;">                       <span class="cm-variable">channel_swap</span>=(<span class="cm-number">2</span>,<span class="cm-number">1</span>,<span class="cm-number">0</span>),</span></pre><pre class=""><span style="padding-right: 0.1px;">                       <span class="cm-variable">raw_scale</span>=<span class="cm-number">255</span>,</span></pre><pre class=""><span style="padding-right: 0.1px;">                       <span class="cm-variable">image_dims</span>=(<span class="cm-number">256</span>, <span class="cm-number">256</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Load the input image into a numpy array and display it</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">input_image</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">io</span>.<span class="cm-variable">load_image</span>(<span class="cm-variable">IMAGE_FILE</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">input_image</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">show</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Calculate how many 256x256 grid squares are in the image</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">rows</span> = <span class="cm-variable">input_image</span>.<span class="cm-variable">shape</span>[<span class="cm-number">0</span>]<span class="cm-operator">/</span><span class="cm-number">256</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">cols</span> = <span class="cm-variable">input_image</span>.<span class="cm-variable">shape</span>[<span class="cm-number">1</span>]<span class="cm-operator">/</span><span class="cm-number">256</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Subtract the mean image</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">rows</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">j</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">cols</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">input_image</span>[<span class="cm-variable">i</span><span class="cm-operator">*</span><span class="cm-number">256</span>:(<span class="cm-variable">i</span><span class="cm-operator">+</span><span class="cm-number">1</span>)<span class="cm-operator">*</span><span class="cm-number">256</span>,<span class="cm-variable">j</span><span class="cm-operator">*</span><span class="cm-number">256</span>:(<span class="cm-variable">j</span><span class="cm-operator">+</span><span class="cm-number">1</span>)<span class="cm-operator">*</span><span class="cm-number">256</span>] -= <span class="cm-variable">mean_image</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Initialize an empty array for the detections</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">detections</span> = <span class="cm-variable">np</span>.<span class="cm-variable">zeros</span>((<span class="cm-variable">rows</span>,<span class="cm-variable">cols</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;">        </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Iterate over each grid square using the model to make a class prediction</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">start</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">rows</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">j</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">cols</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">grid_square</span> = <span class="cm-variable">input_image</span>[<span class="cm-variable">i</span><span class="cm-operator">*</span><span class="cm-number">256</span>:(<span class="cm-variable">i</span><span class="cm-operator">+</span><span class="cm-number">1</span>)<span class="cm-operator">*</span><span class="cm-number">256</span>,<span class="cm-variable">j</span><span class="cm-operator">*</span><span class="cm-number">256</span>:(<span class="cm-variable">j</span><span class="cm-operator">+</span><span class="cm-number">1</span>)<span class="cm-operator">*</span><span class="cm-number">256</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-comment"># make prediction</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">prediction</span> = <span class="cm-variable">net</span>.<span class="cm-variable">predict</span>([<span class="cm-variable">grid_square</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">detections</span>[<span class="cm-variable">i</span>,<span class="cm-variable">j</span>] = <span class="cm-variable">prediction</span>[<span class="cm-number">0</span>].<span class="cm-variable">argmax</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">end</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;">        </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display the predicted class for each grid square</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">detections</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">show</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display total time to perform inference</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">print</span> <span class="cm-string">'Total inference time (sliding window without overlap): '</span> <span class="cm-operator">+</span> <span class="cm-builtin">str</span>(<span class="cm-variable">end</span><span class="cm-operator">-</span><span class="cm-variable">start</span>) <span class="cm-operator">+</span> <span class="cm-string">' seconds'</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># define the amount of overlap between grid cells</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">OVERLAP</span> = <span class="cm-number">0.25</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">grid_rows</span> = <span class="cm-builtin">int</span>((<span class="cm-variable">rows</span><span class="cm-operator">-</span><span class="cm-number">1</span>)<span class="cm-operator">/</span>(<span class="cm-number">1</span><span class="cm-operator">-</span><span class="cm-variable">OVERLAP</span>))<span class="cm-operator">+</span><span class="cm-number">1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">grid_cols</span> = <span class="cm-builtin">int</span>((<span class="cm-variable">cols</span><span class="cm-operator">-</span><span class="cm-number">1</span>)<span class="cm-operator">/</span>(<span class="cm-number">1</span><span class="cm-operator">-</span><span class="cm-variable">OVERLAP</span>))<span class="cm-operator">+</span><span class="cm-number">1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">print</span> <span class="cm-string">"Image has %d*%d blocks of 256 pixels"</span> <span class="cm-operator">%</span> (<span class="cm-variable">rows</span>, <span class="cm-variable">cols</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">print</span> <span class="cm-string">"With overlap=%f grid_size=%d*%d"</span> <span class="cm-operator">%</span> (<span class="cm-variable">OVERLAP</span>, <span class="cm-variable">grid_rows</span>, <span class="cm-variable">grid_cols</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Initialize an empty array for the detections</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">detections</span> = <span class="cm-variable">np</span>.<span class="cm-variable">zeros</span>((<span class="cm-variable">grid_rows</span>,<span class="cm-variable">grid_cols</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Iterate over each grid square using the model to make a class prediction</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">start</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">grid_rows</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">j</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">grid_cols</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">start_col</span> = <span class="cm-variable">j</span><span class="cm-operator">*</span><span class="cm-number">256</span><span class="cm-operator">*</span>(<span class="cm-number">1</span><span class="cm-operator">-</span><span class="cm-variable">OVERLAP</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">start_row</span> = <span class="cm-variable">i</span><span class="cm-operator">*</span><span class="cm-number">256</span><span class="cm-operator">*</span>(<span class="cm-number">1</span><span class="cm-operator">-</span><span class="cm-variable">OVERLAP</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">grid_square</span> = <span class="cm-variable">input_image</span>[<span class="cm-variable">start_row</span>:<span class="cm-variable">start_row</span><span class="cm-operator">+</span><span class="cm-number">256</span>, <span class="cm-variable">start_col</span>:<span class="cm-variable">start_col</span><span class="cm-operator">+</span><span class="cm-number">256</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-comment"># make prediction</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">prediction</span> = <span class="cm-variable">net</span>.<span class="cm-variable">predict</span>([<span class="cm-variable">grid_square</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">detections</span>[<span class="cm-variable">i</span>,<span class="cm-variable">j</span>] = <span class="cm-variable">prediction</span>[<span class="cm-number">0</span>].<span class="cm-variable">argmax</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">end</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;">        </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display the predicted class for each grid square</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">detections</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">show</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display total time to perform inference</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">print</span> (<span class="cm-string">'Total inference time (sliding window with %f%% overlap: '</span> <span class="cm-operator">%</span> (<span class="cm-variable">OVERLAP</span><span class="cm-operator">*</span><span class="cm-number">100</span>)) <span class="cm-operator">+</span> <span class="cm-builtin">str</span>(<span class="cm-variable">end</span><span class="cm-operator">-</span><span class="cm-variable">start</span>) <span class="cm-operator">+</span> <span class="cm-string">' seconds'</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># now with batched inference (one column at a time)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># we are not using a caffe.Classifier here so we need to do the pre-processing</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># manually. The model was trained on random crops (256*256-&gt;227*227) so we</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># need to do the cropping below. Similarly, we need to convert images</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># from Numpy's Height*Width*Channel (HWC) format to Channel*Height*Width (CHW) </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Lastly, we need to swap channels from RGB to BGR</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">net</span> = <span class="cm-variable">caffe</span>.<span class="cm-variable">Net</span>(<span class="cm-variable">MODEL_FILE</span>, <span class="cm-variable">PRETRAINED</span>, <span class="cm-variable">caffe</span>.<span class="cm-variable">TEST</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">start</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">net</span>.<span class="cm-variable">blobs</span>[<span class="cm-string">'data'</span>].<span class="cm-variable">reshape</span>(<span class="cm-operator">*</span>[<span class="cm-variable">grid_cols</span>, <span class="cm-number">3</span>, <span class="cm-number">227</span>, <span class="cm-number">227</span>])</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Initialize an empty array for the detections</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">detections</span> = <span class="cm-variable">np</span>.<span class="cm-variable">zeros</span>((<span class="cm-variable">rows</span>,<span class="cm-variable">cols</span>))</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">rows</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">j</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">cols</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">grid_square</span> = <span class="cm-variable">input_image</span>[<span class="cm-variable">i</span><span class="cm-operator">*</span><span class="cm-number">256</span>:(<span class="cm-variable">i</span><span class="cm-operator">+</span><span class="cm-number">1</span>)<span class="cm-operator">*</span><span class="cm-number">256</span>,<span class="cm-variable">j</span><span class="cm-operator">*</span><span class="cm-number">256</span>:(<span class="cm-variable">j</span><span class="cm-operator">+</span><span class="cm-number">1</span>)<span class="cm-operator">*</span><span class="cm-number">256</span>]</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-comment"># add to batch</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">grid_square</span> = <span class="cm-variable">grid_square</span>[<span class="cm-number">14</span>:<span class="cm-number">241</span>,<span class="cm-number">14</span>:<span class="cm-number">241</span>] <span class="cm-comment"># 227*227 center crop        </span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">image</span> = <span class="cm-variable">np</span>.<span class="cm-variable">copy</span>(<span class="cm-variable">grid_square</span>.<span class="cm-variable">transpose</span>(<span class="cm-number">2</span>,<span class="cm-number">0</span>,<span class="cm-number">1</span>)) <span class="cm-comment"># transpose from HWC to CHW</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">image</span> = <span class="cm-variable">image</span> <span class="cm-operator">*</span> <span class="cm-number">255</span> <span class="cm-comment"># rescale</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">image</span> = <span class="cm-variable">image</span>[(<span class="cm-number">2</span>,<span class="cm-number">1</span>,<span class="cm-number">0</span>), :, :] <span class="cm-comment"># swap channels</span></span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">net</span>.<span class="cm-variable">blobs</span>[<span class="cm-string">'data'</span>].<span class="cm-variable">data</span>[<span class="cm-variable">j</span>] = <span class="cm-variable">image</span></span></pre><pre class=""><span style="padding-right: 0.1px;">    <span class="cm-comment"># make prediction</span></span></pre><pre class=""><span style="padding-right: 0.1px;">    <span class="cm-variable">output</span> = <span class="cm-variable">net</span>.<span class="cm-variable">forward</span>()[<span class="cm-variable">net</span>.<span class="cm-variable">outputs</span>[<span class="cm-operator">-</span><span class="cm-number">1</span>]]</span></pre><pre class=""><span style="padding-right: 0.1px;">    <span class="cm-keyword">for</span> <span class="cm-variable">j</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">0</span>,<span class="cm-variable">cols</span>):</span></pre><pre class=""><span style="padding-right: 0.1px;">        <span class="cm-variable">detections</span>[<span class="cm-variable">i</span>,<span class="cm-variable">j</span>] = <span class="cm-variable">output</span>[<span class="cm-variable">j</span>].<span class="cm-variable">argmax</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">end</span> = <span class="cm-variable">time</span>.<span class="cm-variable">time</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;">        </span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display the predicted class for each grid square</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">imshow</span>(<span class="cm-variable">detections</span>)</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">plt</span>.<span class="cm-variable">show</span>()</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment"># Display total time to perform inference</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">print</span> <span class="cm-string">'Total inference time (batched inference): '</span> <span class="cm-operator">+</span> <span class="cm-builtin">str</span>(<span class="cm-variable">end</span><span class="cm-operator">-</span><span class="cm-variable">start</span>) <span class="cm-operator">+</span> <span class="cm-string">' seconds'</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 2170px;"></div><div class="CodeMirror-gutters" style="display: none; height: 2185px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close" data-vivaldi-spatnav-clickable="1">×</button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" data-vivaldi-spatnav-clickable="1" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" data-vivaldi-spatnav-clickable="1" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 2053px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-link">[Click here]</span><span class="cm-string">(#question-optional-exercise)</span> to return to question</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">id</span>=<span class="cm-string">'answer4'</span><span class="cm-tag cm-bracket">&gt;&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Answer 4</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Replace layers fc6 through fc8 with the following. Then set the <span class="cm-comment">`bottom`</span> blob of the <span class="cm-comment">`loss`</span>, <span class="cm-comment">`accuracy`</span> and <span class="cm-comment">`softmax`</span> layers to <span class="cm-comment">`conv8`</span>.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">```layer {</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">name: "conv6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">type: "Convolution"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">bottom: "pool5"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">top: "conv6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">lr_mult: 1.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">decay_mult: 1.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">lr_mult: 2.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">decay_mult: 0.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">convolution_param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">num_output: 4096</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">pad: 0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">kernel_size: 6</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">weight_filler {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">type: "gaussian"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">std: 0.01</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">bias_filler {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">type: "constant"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">value: 0.1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">layer {</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">name: "relu6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">type: "ReLU"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">bottom: "conv6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">top: "conv6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">layer {</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">name: "drop6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">type: "Dropout"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">bottom: "conv6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">top: "conv6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">dropout_param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">dropout_ratio: 0.5</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">layer {</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">name: "conv7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">type: "Convolution"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">bottom: "conv6"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">top: "conv7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">lr_mult: 1.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">decay_mult: 1.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">lr_mult: 2.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">decay_mult: 0.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">convolution_param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">num_output: 4096</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">kernel_size: 1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">weight_filler {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">type: "gaussian"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">std: 0.01</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">bias_filler {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">type: "constant"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">value: 0.1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">layer {</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">name: "relu7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">type: "ReLU"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">bottom: "conv7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">top: "conv7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">layer {</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">name: "drop7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">type: "Dropout"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">bottom: "conv7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">top: "conv7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">dropout_param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">dropout_ratio: 0.5</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">layer {</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">name: "conv8"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">type: "Convolution"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">bottom: "conv7"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">top: "conv8"</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">lr_mult: 1.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">decay_mult: 1.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">lr_mult: 2.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">decay_mult: 0.0</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">convolution_param {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">num_output: 2</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">kernel_size: 1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">weight_filler {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">type: "gaussian"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">std: 0.01</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">bias_filler {</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">type: "constant"</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp; &nbsp;  <span class="cm-comment">value: 0.1</span></span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;">  <span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">}</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-comment">```</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-link">[Click here]</span><span class="cm-string">(#Exercise:)</span> to return to the exercise</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 2053px;"></div><div class="CodeMirror-gutters" style="display: none; height: 2068px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#question-optional-exercise">Click here</a> to return to question</p>
<p><a id="answer4"></a></p>
<h3 id="Answer-4">Answer 4<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Answer-4">¶</a></h3>
<p>Replace layers fc6 through fc8 with the following. Then set the <code>bottom</code> blob of the <code>loss</code>, <code>accuracy</code> and <code>softmax</code> layers to <code>conv8</code>.</p>
<p><code>layer {
  name: "conv6"
  type: "Convolution"
  bottom: "pool5"
  top: "conv6"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 6
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "conv6"
  top: "conv6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "conv6"
  top: "conv6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv7"
  type: "Convolution"
  bottom: "conv6"
  top: "conv7"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "conv7"
  top: "conv7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "conv7"
  top: "conv7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv8"
  type: "Convolution"
  bottom: "conv7"
  top: "conv8"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}</code></p>
<p><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Exercise:">Click here</a> to return to the exercise</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 234px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 19px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Thanks and data attribution</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">We would like to thank NOAA for their permission to re-use the Right Whale imagery for the purposes of this lab.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Images were collected under MMPA Research permit numbers:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">MMPA 775-1600, &nbsp; &nbsp;  2005-2007</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">MMPA 775-1875, &nbsp; &nbsp;  2008-2013 </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">MMPA 17355, &nbsp; &nbsp; &nbsp; &nbsp; 2013-2018</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Photo Credits: NOAA/NEFSC</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 234px;"></div><div class="CodeMirror-gutters" style="display: none; height: 249px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Thanks-and-data-attribution">Thanks and data attribution<a class="anchor-link" href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#Thanks-and-data-attribution">¶</a></h3>
<p>We would like to thank NOAA for their permission to re-use the Right Whale imagery for the purposes of this lab.</p>
<p>Images were collected under MMPA Research permit numbers:</p>
<p>MMPA 775-1600,      2005-2007</p>
<p>MMPA 775-1875,      2008-2013 </p>
<p>MMPA 17355,         2013-2018</p>
<p>Photo Credits: NOAA/NEFSC</p>
</div></div></div></div><div class="end_space"></div></div>
        <div id="tooltip" class="ipython_tooltip" style="display:none"><div class="tooltipbuttons"><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" role="button" class="ui-button" data-vivaldi-spatnav-clickable="1"><span class="ui-icon ui-icon-close">Close</span></a><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" class="ui-corner-all" role="button" id="expanbutton" title="Grow the tooltip vertically (press shift-tab twice)" data-vivaldi-spatnav-clickable="1"><span class="ui-icon ui-icon-plus">Expand</span></a><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" role="button" class="ui-button" title="show the current docstring in pager (press shift-tab 4 times)" data-vivaldi-spatnav-clickable="1"><span class="ui-icon ui-icon-arrowstop-l-n">Open in Pager</span></a><a href="http://ec2-52-63-128-139.ap-southeast-2.compute.amazonaws.com/6pfqVNhz7HDt/notebooks/Object%20detection.ipynb#" role="button" class="ui-button" title="Tooltip will linger for 10 seconds while you type" data-vivaldi-spatnav-clickable="1" style="display: none;"><span class="ui-icon ui-icon-clock">Close</span></a></div><div class="pretooltiparrow"></div><div class="tooltiptext smalltooltip"></div></div>
    </div>
</div>



</div>



<div id="pager" class="ui-resizable" data-vivaldi-spatnav-clickable="1">
    <div id="pager-contents">
        <div id="pager-container" class="container"></div>
    </div>
    <div id="pager-button-area"><a role="button" title="Open the pager in an external window" class="ui-button" data-vivaldi-spatnav-clickable="1"><span class="ui-icon ui-icon-extlink"></span></a><a role="button" title="Close the pager" class="ui-button" data-vivaldi-spatnav-clickable="1"><span class="ui-icon ui-icon-close"></span></a></div>
<div class="ui-resizable-handle ui-resizable-n" style="z-index: 90;"></div></div>






<script type="text/javascript">
    sys_info = {"os_name": "posix", "sys_version": "2.7.6 (default, Jun 22 2015, 17:58:13) \n[GCC 4.8.2]", "default_encoding": "ANSI_X3.4-1968", "sys_platform": "linux2", "ipython_version": "3.2.1", "ipython_path": "/home/ubuntu/venv/lib/python2.7/site-packages/IPython", "commit_source": "installation", "platform": "Linux-3.13.0-46-generic-x86_64-with-Ubuntu-14.04-trusty", "sys_executable": "/home/ubuntu/venv/bin/python", "commit_hash": "2d95975"};
</script>

<script src="./Object detection_files/encoding.js" charset="utf-8"></script>

<script src="./Object detection_files/main.js" charset="utf-8"></script>





<span style="border-radius: 2px; text-indent: 20px; width: auto; padding: 0px 4px 0px 0px; text-align: center; font-style: normal; font-variant: normal; font-weight: bold; font-stretch: normal; font-size: 11px; line-height: 20px; font-family: &quot;Helvetica Neue&quot;, Helvetica, sans-serif; color: rgb(255, 255, 255); position: absolute; opacity: 1; z-index: 8675309; display: none; cursor: pointer; border: none; -webkit-font-smoothing: antialiased; top: 325px; left: 429px; background: url(&quot;data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMzBweCIgd2lkdGg9IjMwcHgiIHZpZXdCb3g9Ii0xIC0xIDMxIDMxIj48Zz48cGF0aCBkPSJNMjkuNDQ5LDE0LjY2MiBDMjkuNDQ5LDIyLjcyMiAyMi44NjgsMjkuMjU2IDE0Ljc1LDI5LjI1NiBDNi42MzIsMjkuMjU2IDAuMDUxLDIyLjcyMiAwLjA1MSwxNC42NjIgQzAuMDUxLDYuNjAxIDYuNjMyLDAuMDY3IDE0Ljc1LDAuMDY3IEMyMi44NjgsMC4wNjcgMjkuNDQ5LDYuNjAxIDI5LjQ0OSwxNC42NjIiIGZpbGw9IiNmZmYiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxIj48L3BhdGg+PHBhdGggZD0iTTE0LjczMywxLjY4NiBDNy41MTYsMS42ODYgMS42NjUsNy40OTUgMS42NjUsMTQuNjYyIEMxLjY2NSwyMC4xNTkgNS4xMDksMjQuODU0IDkuOTcsMjYuNzQ0IEM5Ljg1NiwyNS43MTggOS43NTMsMjQuMTQzIDEwLjAxNiwyMy4wMjIgQzEwLjI1MywyMi4wMSAxMS41NDgsMTYuNTcyIDExLjU0OCwxNi41NzIgQzExLjU0OCwxNi41NzIgMTEuMTU3LDE1Ljc5NSAxMS4xNTcsMTQuNjQ2IEMxMS4xNTcsMTIuODQyIDEyLjIxMSwxMS40OTUgMTMuNTIyLDExLjQ5NSBDMTQuNjM3LDExLjQ5NSAxNS4xNzUsMTIuMzI2IDE1LjE3NSwxMy4zMjMgQzE1LjE3NSwxNC40MzYgMTQuNDYyLDE2LjEgMTQuMDkzLDE3LjY0MyBDMTMuNzg1LDE4LjkzNSAxNC43NDUsMTkuOTg4IDE2LjAyOCwxOS45ODggQzE4LjM1MSwxOS45ODggMjAuMTM2LDE3LjU1NiAyMC4xMzYsMTQuMDQ2IEMyMC4xMzYsMTAuOTM5IDE3Ljg4OCw4Ljc2NyAxNC42NzgsOC43NjcgQzEwLjk1OSw4Ljc2NyA4Ljc3NywxMS41MzYgOC43NzcsMTQuMzk4IEM4Ljc3NywxNS41MTMgOS4yMSwxNi43MDkgOS43NDksMTcuMzU5IEM5Ljg1NiwxNy40ODggOS44NzIsMTcuNiA5Ljg0LDE3LjczMSBDOS43NDEsMTguMTQxIDkuNTIsMTkuMDIzIDkuNDc3LDE5LjIwMyBDOS40MiwxOS40NCA5LjI4OCwxOS40OTEgOS4wNCwxOS4zNzYgQzcuNDA4LDE4LjYyMiA2LjM4NywxNi4yNTIgNi4zODcsMTQuMzQ5IEM2LjM4NywxMC4yNTYgOS4zODMsNi40OTcgMTUuMDIyLDYuNDk3IEMxOS41NTUsNi40OTcgMjMuMDc4LDkuNzA1IDIzLjA3OCwxMy45OTEgQzIzLjA3OCwxOC40NjMgMjAuMjM5LDIyLjA2MiAxNi4yOTcsMjIuMDYyIEMxNC45NzMsMjIuMDYyIDEzLjcyOCwyMS4zNzkgMTMuMzAyLDIwLjU3MiBDMTMuMzAyLDIwLjU3MiAxMi42NDcsMjMuMDUgMTIuNDg4LDIzLjY1NyBDMTIuMTkzLDI0Ljc4NCAxMS4zOTYsMjYuMTk2IDEwLjg2MywyNy4wNTggQzEyLjA4NiwyNy40MzQgMTMuMzg2LDI3LjYzNyAxNC43MzMsMjcuNjM3IEMyMS45NSwyNy42MzcgMjcuODAxLDIxLjgyOCAyNy44MDEsMTQuNjYyIEMyNy44MDEsNy40OTUgMjEuOTUsMS42ODYgMTQuNzMzLDEuNjg2IiBmaWxsPSIjYmQwODFjIj48L3BhdGg+PC9nPjwvc3ZnPg==&quot;) 3px 50% / 14px 14px no-repeat rgb(189, 8, 28);">Save</span><div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: STIXSizeOneSym, sans-serif;"></div></div></body></html>