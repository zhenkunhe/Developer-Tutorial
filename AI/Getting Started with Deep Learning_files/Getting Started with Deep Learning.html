<!DOCTYPE html>
<!-- saved from url=(0131)http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb# -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

    <title>Getting Started with Deep Learning</title>
    <link rel="shortcut icon" type="image/x-icon" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/static/base/images/favicon.ico?v=30780f272ab4aac64aa073a841546240">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link rel="stylesheet" href="./Getting Started with Deep Learning_files/jquery-ui.min.css" type="text/css">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    


<script type="text/javascript" src="./Getting Started with Deep Learning_files/MathJax.js" charset="utf-8"></script>

<script type="text/javascript">
// MathJax disabled, set as null to distingish from *missing* MathJax,
// where it will be undefined, and should prompt a dialog later.
window.mathjax_url = "/L8Ljs7G2/static/mathjax/MathJax.js";
</script>

<link rel="stylesheet" href="./Getting Started with Deep Learning_files/bootstrap-tour.min.css" type="text/css">
<link rel="stylesheet" href="./Getting Started with Deep Learning_files/codemirror.css">


    <link rel="stylesheet" href="./Getting Started with Deep Learning_files/style.min.css" type="text/css">
    

<link rel="stylesheet" href="./Getting Started with Deep Learning_files/override.css" type="text/css">
<link rel="stylesheet" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb" id="kernel-css" type="text/css">


    <link rel="stylesheet" href="./Getting Started with Deep Learning_files/custom.css" type="text/css">
    <script src="./Getting Started with Deep Learning_files/promise.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="./Getting Started with Deep Learning_files/require.js" type="text/javascript" charset="utf-8"></script>
    <script>
      require.config({
          
          urlArgs: "v=20161021053601",
          
          baseUrl: '/L8Ljs7G2/static/',
          paths: {
            nbextensions : '/L8Ljs7G2/nbextensions',
            kernelspecs : '/L8Ljs7G2/kernelspecs',
            underscore : 'components/underscore/underscore-min',
            backbone : 'components/backbone/backbone-min',
            jquery: 'components/jquery/jquery.min',
            bootstrap: 'components/bootstrap/js/bootstrap.min',
            bootstraptour: 'components/bootstrap-tour/build/js/bootstrap-tour.min',
            jqueryui: 'components/jquery-ui/ui/minified/jquery-ui.min',
            moment: 'components/moment/moment',
            codemirror: 'components/codemirror',
            termjs: 'components/term.js/src/term',
          },
          shim: {
            underscore: {
              exports: '_'
            },
            backbone: {
              deps: ["underscore", "jquery"],
              exports: "Backbone"
            },
            bootstrap: {
              deps: ["jquery"],
              exports: "bootstrap"
            },
            bootstraptour: {
              deps: ["bootstrap"],
              exports: "Tour"
            },
            jqueryui: {
              deps: ["jquery"],
              exports: "$"
            }
          }
      });

      require.config({
          map: {
              '*':{
                'contents': 'services/contents',
              }
          }
      });
    </script>

    
    

<script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/namespace" src="./Getting Started with Deep Learning_files/namespace.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="jquery" src="./Getting Started with Deep Learning_files/jquery.min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/notebook" src="./Getting Started with Deep Learning_files/notebook.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/contents" src="./Getting Started with Deep Learning_files/contents.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/config" src="./Getting Started with Deep Learning_files/config.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/utils" src="./Getting Started with Deep Learning_files/utils.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/page" src="./Getting Started with Deep Learning_files/page.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/events" src="./Getting Started with Deep Learning_files/events.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="auth/js/loginwidget" src="./Getting Started with Deep Learning_files/loginwidget.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/maintoolbar" src="./Getting Started with Deep Learning_files/maintoolbar.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/pager" src="./Getting Started with Deep Learning_files/pager.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/quickhelp" src="./Getting Started with Deep Learning_files/quickhelp.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/menubar" src="./Getting Started with Deep Learning_files/menubar.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/notificationarea" src="./Getting Started with Deep Learning_files/notificationarea.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/savewidget" src="./Getting Started with Deep Learning_files/savewidget.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/actions" src="./Getting Started with Deep Learning_files/actions.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/keyboardmanager" src="./Getting Started with Deep Learning_files/keyboardmanager.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/kernelselector" src="./Getting Started with Deep Learning_files/kernelselector.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/lib/codemirror" src="./Getting Started with Deep Learning_files/codemirror.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/about" src="./Getting Started with Deep Learning_files/about.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="custom/custom" src="./Getting Started with Deep Learning_files/custom.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/dialog" src="./Getting Started with Deep Learning_files/dialog.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/cell" src="./Getting Started with Deep Learning_files/cell.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/textcell" src="./Getting Started with Deep Learning_files/textcell.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/codecell" src="./Getting Started with Deep Learning_files/codecell.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="moment" src="./Getting Started with Deep Learning_files/moment.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/sessions/session" src="./Getting Started with Deep Learning_files/session.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/celltoolbar" src="./Getting Started with Deep Learning_files/celltoolbar.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="components/marked/lib/marked" src="./Getting Started with Deep Learning_files/marked.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/runmode/runmode" src="./Getting Started with Deep Learning_files/runmode.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/mathjaxutils" src="./Getting Started with Deep Learning_files/mathjaxutils.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/keyboard" src="./Getting Started with Deep Learning_files/keyboard.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/tooltip" src="./Getting Started with Deep Learning_files/tooltip.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/celltoolbarpresets/default" src="./Getting Started with Deep Learning_files/default.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/celltoolbarpresets/rawcell" src="./Getting Started with Deep Learning_files/rawcell.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/celltoolbarpresets/slideshow" src="./Getting Started with Deep Learning_files/slideshow.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/scrollmanager" src="./Getting Started with Deep Learning_files/scrollmanager.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/meta" src="./Getting Started with Deep Learning_files/meta.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/toolbar" src="./Getting Started with Deep Learning_files/toolbar.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/tour" src="./Getting Started with Deep Learning_files/tour.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/notificationarea" src="./Getting Started with Deep Learning_files/notificationarea(1).js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/edit/matchbrackets" src="./Getting Started with Deep Learning_files/matchbrackets.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/edit/closebrackets" src="./Getting Started with Deep Learning_files/closebrackets.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/comment/comment" src="./Getting Started with Deep Learning_files/comment.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/security" src="./Getting Started with Deep Learning_files/security.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/gfm/gfm" src="./Getting Started with Deep Learning_files/gfm.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/codemirror-ipythongfm" src="./Getting Started with Deep Learning_files/codemirror-ipythongfm.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/outputarea" src="./Getting Started with Deep Learning_files/outputarea.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/completer" src="./Getting Started with Deep Learning_files/completer.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/python/python" src="./Getting Started with Deep Learning_files/python.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/codemirror-ipython" src="./Getting Started with Deep Learning_files/codemirror-ipython.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/kernels/kernel" src="./Getting Started with Deep Learning_files/kernel.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="base/js/notificationwidget" src="./Getting Started with Deep Learning_files/notificationwidget.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="jqueryui" src="./Getting Started with Deep Learning_files/jquery-ui.min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="bootstrap" src="./Getting Started with Deep Learning_files/bootstrap.min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="components/google-caja/html-css-sanitizer-minified" src="./Getting Started with Deep Learning_files/html-css-sanitizer-minified.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/markdown/markdown" src="./Getting Started with Deep Learning_files/markdown.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/mode/overlay" src="./Getting Started with Deep Learning_files/overlay.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/addon/mode/multiplex" src="./Getting Started with Deep Learning_files/multiplex.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/stex/stex" src="./Getting Started with Deep Learning_files/stex.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="notebook/js/contexthint" src="./Getting Started with Deep Learning_files/contexthint.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/kernels/comm" src="./Getting Started with Deep Learning_files/comm.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="services/kernels/serialize" src="./Getting Started with Deep Learning_files/serialize.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/init" src="./Getting Started with Deep Learning_files/init.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="underscore" src="./Getting Started with Deep Learning_files/underscore-min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="bootstraptour" src="./Getting Started with Deep Learning_files/bootstrap-tour.min.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="codemirror/mode/xml/xml" src="./Getting Started with Deep Learning_files/xml.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/manager" src="./Getting Started with Deep Learning_files/manager.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_link" src="./Getting Started with Deep Learning_files/widget_link.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_bool" src="./Getting Started with Deep Learning_files/widget_bool.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_button" src="./Getting Started with Deep Learning_files/widget_button.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_box" src="./Getting Started with Deep Learning_files/widget_box.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_float" src="./Getting Started with Deep Learning_files/widget_float.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_image" src="./Getting Started with Deep Learning_files/widget_image.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_int" src="./Getting Started with Deep Learning_files/widget_int.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_output" src="./Getting Started with Deep Learning_files/widget_output.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_selection" src="./Getting Started with Deep Learning_files/widget_selection.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_selectioncontainer" src="./Getting Started with Deep Learning_files/widget_selectioncontainer.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget_string" src="./Getting Started with Deep Learning_files/widget_string.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="widgets/js/widget" src="./Getting Started with Deep Learning_files/widget.js"></script><script type="text/javascript" charset="utf-8" async="" data-requirecontext="_" data-requiremodule="backbone" src="./Getting Started with Deep Learning_files/backbone-min.js"></script><style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Hover_Arrow {position: absolute; width: 15px; height: 11px; cursor: pointer}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 5px 0px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; -khtml-border-radius: 5px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 1px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; color: #666666}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: .7em}
.MathJax_MenuRadioCheck.RTL {right: .7em; left: auto}
.MathJax_MenuLabel {padding: 1px 2em 3px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #DDDDDD; margin: 4px 3px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: #606872; color: white}
.MathJax_Menu_Close {position: absolute; width: 31px; height: 31px; top: -15px; left: -15px}
</style><style type="text/css">.MathJax_Preview .MJXc-math {color: inherit!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style id="style-1-cropbar-clipper">/* Copyright 2014 Evernote Corporation. All rights reserved. */
.en-markup-crop-options {
    top: 18px !important;
    left: 50% !important;
    margin-left: -100px !important;
    width: 200px !important;
    border: 2px rgba(255,255,255,.38) solid !important;
    border-radius: 4px !important;
}

.en-markup-crop-options div div:first-of-type {
    margin-left: 0px !important;
}
</style><style type="text/css">.MJXc-script {font-size: .8em}
.MJXc-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXc-bold {font-weight: bold}
.MJXc-italic {font-style: italic}
.MJXc-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXc-largeop {font-size: 150%}
.MJXc-largeop.MJXc-int {vertical-align: -.2em}
.MJXc-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXc-display {display: block; text-align: center; margin: 1em 0}
.MJXc-math span {display: inline-block}
.MJXc-box {display: block!important; text-align: center}
.MJXc-box:after {content: " "}
.MJXc-rule {display: block!important; margin-top: .1em}
.MJXc-char {display: block!important}
.MJXc-mo {margin: 0 .15em}
.MJXc-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXc-denom {display: inline-table!important; width: 100%}
.MJXc-denom > * {display: table-row!important}
.MJXc-surd {vertical-align: top}
.MJXc-surd > * {display: block!important}
.MJXc-script-box > *  {display: table!important; height: 50%}
.MJXc-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXc-script-box > *:last-child > * {vertical-align: bottom}
.MJXc-script-box > * > * > * {display: block!important}
.MJXc-mphantom {visibility: hidden}
.MJXc-munderover {display: inline-table!important}
.MJXc-over {display: inline-block!important; text-align: center}
.MJXc-over > * {display: block!important}
.MJXc-munderover > * {display: table-row!important}
.MJXc-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXc-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXc-mtr {display: table-row!important}
.MJXc-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXc-mtr > .MJXc-mtd:first-child {padding-left: 0}
.MJXc-mtr:first-child > .MJXc-mtd {padding-top: 0}
.MJXc-mlabeledtr {display: table-row!important}
.MJXc-mlabeledtr > .MJXc-mtd:first-child {padding-left: 0}
.MJXc-mlabeledtr:first-child > .MJXc-mtd {padding-top: 0}
.MJXc-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXc-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXc-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXc-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXc-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXc-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXc-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXc-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXc-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXc-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXc-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_CHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><style type="text/css">.MathJax_Display {text-align: center; margin: 0; position: relative; display: block!important; text-indent: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; width: 100%}
.MathJax .merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MathJax .MJX-monospace {font-family: monospace}
.MathJax .MJX-sans-serif {font-family: sans-serif}
#MathJax_Tooltip {background-color: InfoBackground; color: InfoText; border: 1px solid black; box-shadow: 2px 2px 5px #AAAAAA; -webkit-box-shadow: 2px 2px 5px #AAAAAA; -moz-box-shadow: 2px 2px 5px #AAAAAA; -khtml-box-shadow: 2px 2px 5px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true'); padding: 3px 4px; z-index: 401; position: absolute; left: 0; top: 0; width: auto; height: auto; display: none}
.MathJax {display: inline; font-style: normal; font-weight: normal; line-height: normal; font-size: 100%; font-size-adjust: none; text-indent: 0; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; padding: 0; margin: 0}
.MathJax img, .MathJax nobr, .MathJax a {border: 0; padding: 0; margin: 0; max-width: none; max-height: none; min-width: 0; min-height: 0; vertical-align: 0; line-height: normal; text-decoration: none}
img.MathJax_strut {border: 0!important; padding: 0!important; margin: 0!important; vertical-align: 0!important}
.MathJax span {display: inline; position: static; border: 0; padding: 0; margin: 0; vertical-align: 0; line-height: normal; text-decoration: none}
.MathJax nobr {white-space: nowrap!important}
.MathJax img {display: inline!important; float: none!important}
.MathJax * {transition: none; -webkit-transition: none; -moz-transition: none; -ms-transition: none; -o-transition: none}
.MathJax_Processing {visibility: hidden; position: fixed; width: 0; height: 0; overflow: hidden}
.MathJax_Processed {display: none!important}
.MathJax_ExBox {display: block!important; overflow: hidden; width: 1px; height: 60ex; min-height: 0; max-height: none}
.MathJax .MathJax_EmBox {display: block!important; overflow: hidden; width: 1px; height: 60em; min-height: 0; max-height: none}
.MathJax .MathJax_HitBox {cursor: text; background: white; opacity: 0; filter: alpha(opacity=0)}
.MathJax .MathJax_HitBox * {filter: none; opacity: 1; background: transparent}
#MathJax_Tooltip * {filter: none; opacity: 1; background: transparent}
@font-face {font-family: MathJax_Blank; src: url('about:blank')}
.MathJax .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style></head>

<body class="notebook_app  command_mode ctb_global_show" data-project="" data-base-url="/L8Ljs7G2/" data-ws-url="" data-notebook-name="Getting%20Started%20with%20Deep%20Learning.ipynb" data-notebook-path="Getting%20Started%20with%20Deep%20Learning.ipynb" data-pinterest-extension-installed="cr2.0.4" style=""><div style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"><div id="MathJax_Hidden"></div></div><div id="MathJax_Message" style="display: none;"></div>

<noscript>
    &lt;div id='noscript'&gt;
      IPython Notebook requires JavaScript.&lt;br&gt;
      Please enable it to proceed.
  &lt;/div&gt;
</noscript>

<div id="header" style="display: block;">
  <div id="header-container" class="container">
  <div id="ipython_notebook" class="nav navbar-brand pull-left"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/tree" title="dashboard"><img src="./Getting Started with Deep Learning_files/logo.png" alt="Jupyter Notebook" data-pin-nopin="true"></a></div>

  

  

    <span id="login_widget">
      
    </span>

  

  

  


<span id="save_widget" class="pull-left save_widget">
    <span id="notebook_name" class="filename">Getting Started with Deep Learning</span>
    <span class="checkpoint_status" title="no checkpoint"></span>
    <span class="autosave_status">(autosaved)</span>
</span>

<span id="kernel_logo_widget">
  <img class="current_kernel_logo" src="./Getting Started with Deep Learning_files/logo-64x64.png" style="display: inline;" data-pin-nopin="true">
</span>


  </div>
  <div class="header-bar"></div>

  
<div id="menubar-container" class="container">
<div id="menubar">
    <div id="menus" class="navbar navbar-default" role="navigation">
        <div class="container-fluid">
            <button type="button" class="btn btn-default navbar-btn navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
              <i class="fa fa-bars"></i>
              <span class="navbar-text">Menu</span>
            </button>
            <p id="kernel_indicator" class="navbar-text indicator_area">
              <span class="kernel_indicator_name">Python 2</span>
              <i id="kernel_indicator_icon" class="kernel_idle_icon" title="Kernel Idle"></i>
            </p>
            <i id="readonly-indicator" class="navbar-text" title="This notebook is read-only" style="display: none;">
                <span class="fa-stack">
                    <i class="fa fa-save fa-stack-1x"></i>
                    <i class="fa fa-ban fa-stack-2x text-danger"></i>
                </span>
            </i>
            <i id="modal_indicator" class="navbar-text modal_indicator" title="Command Mode"></i>
            <span id="notification_area"><div id="notification_kernel" class="notification_widget btn btn-xs navbar-btn undefined info" style="display: none;" data-vivaldi-spatnav-clickable="1"><span></span></div><div id="notification_notebook" class="notification_widget btn btn-xs navbar-btn" style="display: none;" data-vivaldi-spatnav-clickable="1"><span></span></div></span>
            <div class="navbar-collapse collapse">
              <ul class="nav navbar-nav">
                <li class="dropdown"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" class="dropdown-toggle" data-toggle="dropdown" aria-expanded="false">File</a>
                    <ul id="file_menu" class="dropdown-menu">
                        <li id="new_notebook" class="dropdown-submenu">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">New Notebook</a>
                            <ul class="dropdown-menu" id="menu-new-notebook-submenu"><li id="new-notebook-submenu-python2"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" data-vivaldi-spatnav-clickable="1">Python 2</a></li><li class="divider"></li><li id="new-notebook-submenu-itorch"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" data-vivaldi-spatnav-clickable="1">iTorch</a></li></ul>
                        </li>
                        <li id="open_notebook" title="Opens a new window with the Dashboard view">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Open...</a></li>
                        <!-- <hr/> -->
                        <li class="divider"></li>
                        <li id="copy_notebook" title="Open a copy of this notebook&#39;s contents and start a new kernel">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Make a Copy...</a></li>
                        <li id="rename_notebook"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Rename...</a></li>
                        <li id="save_checkpoint"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Save and Checkpoint</a></li>
                        <!-- <hr/> -->
                        <li class="divider"></li>
                        <li id="restore_checkpoint" class="dropdown-submenu"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Revert to Checkpoint</a>
                          <ul class="dropdown-menu"><li class="disabled"><a>No checkpoints</a></li></ul>
                        </li>
                        <li class="divider"></li>
                        <li id="print_preview"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Print Preview</a></li>
                        <li class="dropdown-submenu"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Download as</a>
                            <ul class="dropdown-menu">
                                <li id="download_ipynb"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">IPython Notebook (.ipynb)</a></li>
                                <li id="download_script"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Python (.py)</a></li>
                                <li id="download_html"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">HTML (.html)</a></li>
                                <li id="download_markdown"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Markdown (.md)</a></li>
                                <li id="download_rst"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">reST (.rst)</a></li>
                                <li id="download_pdf"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">PDF via LaTeX (.pdf)</a></li>
                            </ul>
                        </li>
                        <li class="divider"></li>
                        <li id="trust_notebook" title="Trust the output of this notebook">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Trust Notebook</a></li>
                        <li class="divider"></li>
                        <li id="kill_and_exit" title="Shutdown this notebook&#39;s kernel, and close this window">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Close and Halt</a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Edit</a>
                    <ul id="edit_menu" class="dropdown-menu">
                        <li id="cut_cell"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Cut Cell</a></li>
                        <li id="copy_cell"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Copy Cell</a></li>
                        <li id="paste_cell_above" class="disabled"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Paste Cell Above</a></li>
                        <li id="paste_cell_below" class="disabled"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Paste Cell Below</a></li>
                        <li id="paste_cell_replace" class="disabled"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Paste Cell &amp; Replace</a></li>
                        <li id="delete_cell"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Delete Cell</a></li>
                        <li id="undelete_cell" class="disabled"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Undo Delete Cell</a></li>
                        <li class="divider"></li>
                        <li id="split_cell"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Split Cell</a></li>
                        <li id="merge_cell_above"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Merge Cell Above</a></li>
                        <li id="merge_cell_below"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Merge Cell Below</a></li>
                        <li class="divider"></li>
                        <li id="move_cell_up"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Move Cell Up</a></li>
                        <li id="move_cell_down"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Move Cell Down</a></li>
                        <li class="divider"></li>
                        <li id="edit_nb_metadata"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Edit Notebook Metadata</a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" class="dropdown-toggle" data-toggle="dropdown" aria-expanded="false">View</a>
                    <ul id="view_menu" class="dropdown-menu">
                        <li id="toggle_header" title="Show/Hide the IPython Notebook logo and notebook title (above menu bar)">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Toggle Header</a></li>
                        <li id="toggle_toolbar" title="Show/Hide the action icons (below menu bar)">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Toggle Toolbar</a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Insert</a>
                    <ul id="insert_menu" class="dropdown-menu">
                        <li id="insert_cell_above" title="Insert an empty Code cell above the currently active cell">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Insert Cell Above</a></li>
                        <li id="insert_cell_below" title="Insert an empty Code cell below the currently active cell">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Insert Cell Below</a></li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Cell</a>
                    <ul id="cell_menu" class="dropdown-menu">
                        <li id="run_cell" title="Run this cell, and move cursor to the next one">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Run</a></li>
                        <li id="run_cell_select_below" title="Run this cell, select below">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Run and Select Below</a></li>
                        <li id="run_cell_insert_below" title="Run this cell, insert below">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Run and Insert Below</a></li>
                        <li id="run_all_cells" title="Run all cells in the notebook">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Run All</a></li>
                        <li id="run_all_cells_above" title="Run all cells above (but not including) this cell">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Run All Above</a></li>
                        <li id="run_all_cells_below" title="Run this cell and all cells below it">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Run All Below</a></li>
                        <li class="divider"></li>
                        <li id="change_cell_type" class="dropdown-submenu" title="All cells in the notebook have a cell type. By default, new cells are created as &#39;Code&#39; cells">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Cell Type</a>
                            <ul class="dropdown-menu">
                              <li id="to_code" title="Contents will be sent to the kernel for execution, and output will display in the footer of cell">
                                  <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Code</a></li>
                              <li id="to_markdown" title="Contents will be rendered as HTML and serve as explanatory text">
                                  <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Markdown</a></li>
                              <li id="to_raw" title="Contents will pass through nbconvert unmodified">
                                  <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Raw NBConvert</a></li>
                            </ul>
                        </li>
                        <li class="divider"></li>
                        <li id="current_outputs" class="dropdown-submenu"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Current Output</a>
                            <ul class="dropdown-menu">
                                <li id="toggle_current_output" title="Hide/Show the output of the current cell">
                                    <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Toggle</a>
                                </li>
                                <li id="toggle_current_output_scroll" title="Scroll the output of the current cell">
                                    <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Toggle Scrolling</a>
                                </li>
                                <li id="clear_current_output" title="Clear the output of the current cell">
                                    <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Clear</a>
                                </li>
                            </ul>
                        </li>
                        <li id="all_outputs" class="dropdown-submenu"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">All Output</a>
                            <ul class="dropdown-menu">
                                <li id="toggle_all_output" title="Hide/Show the output of all cells">
                                    <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Toggle</a>
                                </li>
                                <li id="toggle_all_output_scroll" title="Scroll the output of all cells">
                                    <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Toggle Scrolling</a>
                                </li>
                                <li id="clear_all_output" title="Clear the output of all cells">
                                    <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Clear</a>
                                </li>
                            </ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Kernel</a>
                    <ul id="kernel_menu" class="dropdown-menu">
                        <li id="int_kernel" title="Send KeyboardInterrupt (CTRL-C) to the Kernel">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Interrupt</a>
                        </li>
                        <li id="restart_kernel" title="Restart the Kernel">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Restart</a>
                        </li>
                        <li id="reconnect_kernel" title="Reconnect to the Kernel">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Reconnect</a>
                        </li>
                        <li class="divider"></li>
                        <li id="menu-change-kernel" class="dropdown-submenu">
                            <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Change kernel</a>
                            <ul class="dropdown-menu" id="menu-change-kernel-submenu"><li id="kernel-submenu-python2"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" data-vivaldi-spatnav-clickable="1">Python 2</a></li><li id="kernel-submenu-itorch"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" data-vivaldi-spatnav-clickable="1">iTorch</a></li></ul>
                        </li>
                    </ul>
                </li>
                <li class="dropdown"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" class="dropdown-toggle" data-toggle="dropdown">Help</a>
                    <ul id="help_menu" class="dropdown-menu">
                        <li id="notebook_tour" title="A quick tour of the notebook user interface"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">User Interface Tour</a></li>
                        <li id="keyboard_shortcuts" title="Opens a tooltip with all keyboard shortcuts"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">Keyboard Shortcuts</a></li>
                        <li class="divider"></li>
                        

                        
                            
                                <li><a href="http://nbviewer.ipython.org/github/ipython/ipython/blob/3.x/examples/Notebook/Index.ipynb" target="_blank" title="Opens in a new window">
                                <i class="fa fa-external-link menu-icon pull-right"></i>
                                Notebook Help
                                </a></li>
                            
                                <li><a href="https://help.github.com/articles/markdown-basics/" target="_blank" title="Opens in a new window">
                                <i class="fa fa-external-link menu-icon pull-right"></i>
                                Markdown
                                </a></li>
                            
                            
                        
                        <li id="kernel-help-links" class="divider"></li><li><a target="_blank" title="Opens in a new window" href="http://docs.python.org/2.7"><i class="fa fa-external-link menu-icon pull-right"></i><span>Python</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://ipython.org/documentation.html"><i class="fa fa-external-link menu-icon pull-right"></i><span>IPython</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.scipy.org/doc/numpy/reference/"><i class="fa fa-external-link menu-icon pull-right"></i><span>NumPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.scipy.org/doc/scipy/reference/"><i class="fa fa-external-link menu-icon pull-right"></i><span>SciPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://matplotlib.org/contents.html"><i class="fa fa-external-link menu-icon pull-right"></i><span>Matplotlib</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://docs.sympy.org/latest/index.html"><i class="fa fa-external-link menu-icon pull-right"></i><span>SymPy</span></a></li><li><a target="_blank" title="Opens in a new window" href="http://pandas.pydata.org/pandas-docs/stable/"><i class="fa fa-external-link menu-icon pull-right"></i><span>pandas</span></a></li><li class="divider"></li>
                        <li title="About IPython Notebook"><a id="notebook_about" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#">About</a></li>
                    </ul>
                </li>
              </ul>
            </div>
        </div>
    </div>
</div>

<div id="maintoolbar" class="navbar">
  <div class="toolbar-inner navbar-inner navbar-nobg">
    <div id="maintoolbar-container" class="container toolbar"><div class="btn-group" id="save-notbook"><button class="btn btn-default" title="Save and Checkpoint" data-jupyter-action="ipython.save-notebook"><i class="fa-save fa"></i></button></div><div class="btn-group" id="insert_above_below"><button class="btn btn-default" title="insert cell below" data-jupyter-action="ipython.insert-cell-after"><i class="fa-plus fa"></i></button></div><div class="btn-group" id="cut_copy_paste"><button class="btn btn-default" title="cut selected cell" data-jupyter-action="ipython.cut-selected-cell"><i class="fa-cut fa"></i></button><button class="btn btn-default" title="copy selected cell" data-jupyter-action="ipython.copy-selected-cell"><i class="fa-copy fa"></i></button><button class="btn btn-default" title="paste cell below" data-jupyter-action="ipython.paste-cell-after"><i class="fa-paste fa"></i></button></div><div class="btn-group" id="move_up_down"><button class="btn btn-default" title="move selected cell up" data-jupyter-action="ipython.move-selected-cell-up"><i class="fa-arrow-up fa"></i></button><button class="btn btn-default" title="move selected cell down" data-jupyter-action="ipython.move-selected-cell-down"><i class="fa-arrow-down fa"></i></button></div><div class="btn-group" id="run_int"><button class="btn btn-default" title="run cell, select below" data-jupyter-action="ipython.run-select-next"><i class="fa-play fa"></i></button><button class="btn btn-default" title="interrupt kernel" data-jupyter-action="ipython.interrupt-kernel"><i class="fa-stop fa"></i></button><button class="btn btn-default" title="restart kernel" data-jupyter-action="ipython.restart-kernel"><i class="fa-repeat fa"></i></button></div><select id="cell_type" class="form-control select-xs"><option value="code">Code</option><option value="markdown">Markdown</option><option value="raw">Raw NBConvert</option><option value="heading">Heading</option></select><div class="btn-group"><span class="navbar-text">Cell Toolbar:</span><select id="ctb_select" class="form-control select-xs"><option value="">None</option><option value="Edit Metadata">Edit Metadata</option><option value="Raw Cell Format">Raw Cell Format</option><option value="Slideshow">Slideshow</option></select></div></div>
  </div>
</div>
</div>

<div class="lower-header-bar"></div>

</div>

<div id="site" style="display: block; height: 621px;">


<div id="ipython-main-app">
    <div id="notebook_panel">
        <div id="notebook" tabindex="-1"><div class="container" id="notebook-container"><div class="cell text_cell rendered selected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 31px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Getting Started With Deep Learning</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 31px;"></div><div class="CodeMirror-gutters" style="display: none; height: 46px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Getting-Started-With-Deep-Learning">Getting Started With Deep Learning<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Getting-Started-With-Deep-Learning">¶</a></h2>
</div></div></div><div class="cell text_cell rendered unselected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;">By Craig Tierney</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>By Craig Tierney</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 30px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 19px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Overview</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 30px;"></div><div class="CodeMirror-gutters" style="display: none; height: 45px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Overview">Overview<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Overview">¶</a></h3>
</div></div></div><div class="cell text_cell rendered unselected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 181px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 16.5px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;">Deep learning is allowing machines to acheive near human levels of visual recognition capabilities and disrupting many applications by replacing hand-coded software with predictive models learned directly from data.  This lab introduces the machine learning workflow and provides hands-on experience with using deep neural networks (DNN) to solve a challenging real-world image classification problem.  We will work through all phases of the deep learning workflow including data preprocessing, training, evaluation, and methods to improve training accuracy including data augmentation and network optimization. You will also see the benefits of GPU acceleration in the model training process.  On completion of this lab you will have the knowledge to train a DNN on your own image classification dataset.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 181px;"></div><div class="CodeMirror-gutters" style="display: none; height: 196px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>Deep learning is allowing machines to acheive near human levels of visual recognition capabilities and disrupting many applications by replacing hand-coded software with predictive models learned directly from data.  This lab introduces the machine learning workflow and provides hands-on experience with using deep neural networks (DNN) to solve a challenging real-world image classification problem.  We will work through all phases of the deep learning workflow including data preprocessing, training, evaluation, and methods to improve training accuracy including data augmentation and network optimization. You will also see the benefits of GPU acceleration in the model training process.  On completion of this lab you will have the knowledge to train a DNN on your own image classification dataset.</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 218px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Verify your Run Environment</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Before we begin, let's verify <span class="cm-link">[WebSockets]</span><span class="cm-string">(http://en.wikipedia.org/wiki/WebSocket)</span> are working on your system.  To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see some output returned below the grey cell.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">You will know the lab is processing when you see a solid circle in the top-right of the window that looks like this: <span class="cm-tag">![]</span><span class="cm-string">(images/jupyter_executing.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Otherwise, when it is idle, you will see the following: <span class="cm-tag">![]</span><span class="cm-string">(images/jupyter_idle.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;">For troubleshooting, please see <span class="cm-link">[Self-paced Lab Troubleshooting FAQ]</span><span class="cm-string">(https://developer.nvidia.com/self-paced-labs-faq#Troubleshooting)</span> to debug the issue.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 218px;"></div><div class="CodeMirror-gutters" style="display: none; height: 233px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Verify-your-Run-Environment">Verify your Run Environment<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Verify-your-Run-Environment">¶</a></h2>
<p>Before we begin, let's verify <a href="http://en.wikipedia.org/wiki/WebSocket" target="_blank">WebSockets</a> are working on your system.  To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see some output returned below the grey cell.  </p>
<p>You will know the lab is processing when you see a solid circle in the top-right of the window that looks like this: <img src="./Getting Started with Deep Learning_files/jupyter_executing.png" alt="" data-pin-nopin="true">
Otherwise, when it is idle, you will see the following: <img src="./Getting Started with Deep Learning_files/jupyter_idle.png" alt="">
For troubleshooting, please see <a href="https://developer.nvidia.com/self-paced-labs-faq#Troubleshooting" target="_blank">Self-paced Lab Troubleshooting FAQ</a> to debug the issue.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 397.75px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre><span style="padding-right: 0.1px;"><span class="cm-keyword">print</span> <span class="cm-string">"The answer should be three: "</span> <span class="cm-operator">+</span> <span class="cm-builtin">str</span>(<span class="cm-number">1</span><span class="cm-operator">+</span><span class="cm-number">2</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close" data-vivaldi-spatnav-clickable="1">×</button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" data-vivaldi-spatnav-clickable="1" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" data-vivaldi-spatnav-clickable="1" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;">Let's execute the cell below to display information about the GPUs running on the server.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>Let's execute the cell below to display information about the GPUs running on the server.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 95px; margin-bottom: -15px; border-right-width: 15px; min-height: 28px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre><span style="padding-right: 0.1px;"><span class="cm-operator">!</span><span class="cm-variable">nvidia</span><span class="cm-operator">-</span><span class="cm-variable">smi</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 28px;"></div><div class="CodeMirror-gutters" style="display: none; height: 43px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close" data-vivaldi-spatnav-clickable="1">×</button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to scroll output; double click to hide" data-vivaldi-spatnav-clickable="1" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" data-vivaldi-spatnav-clickable="1" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 847px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Introduction to Deep Learning</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Deep learning is the use of many hidden layers in an artificial neural network to train a model to learn and understand the data without an inherent understanding of what the data are.  deep learning is being used by many different disciplines to allow computers to learn from vast amounts of data.  Recent advances in computer vision, object detection and natural language processing can be attributed to the adoption of Deep Learning techniques.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">One key to the success of deep learning is the convolutional neural network (CNN).  In a traditional neural network, a artificial neurons in a layer are fully connected to the previous and next layer.  In a <span class="cm-link">[convolutional neural network]</span><span class="cm-string">(http://en.wikipedia.org/wiki/Convolutional_neural_network)</span>, overlapping regions of the network are associated instead of the entire layer.  Biologically inspired, a convolutional network acts as filters to process pieces of data.  The result is that these networks can act as feature extractors at both coarse and fine scales eliminating the need to design custom feature extractors as was done previously in traditional computer vision.  CNNs can be trained to recognize structure in large sets of data including images, voice, and text.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-b"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The workflow of deep learning is a multi-phase, iterative process.  First, data must be gathered and pre-processed.  While the Internet and big data have provide access to massive quantities of data, the data often need to be verified, labeled, and pre-processed for consistency.  Second, the data are used to train a network.  Pre-existing networks can be used or new ones can be developed.  Both the network and the training process have many variables that can be modified and tuned which affect the training rate and accuracy.  Third, models need to be tested to verify they are working as expected.  Often at this point one iteriates over the steps to improve the results.  This includes Reprocessing data, modifying networks, modifying parameters of the networks or solvers, and retesting until the desired results are obtained.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In this tutorial today, you will work through all phases of the deep learning workflow to solve a classic machine learning problem, text recognition.  We will be using a multi-layer convolutional neural network to train our model to recognize handwritten digits from the [MNIST] (<span class="cm-link">http://yann.lecun.com/exdb/mnist/</span>) database. The MNIST database contains thousands of images of handwritten numbers from 0 to 9.  This dataset has been used by both those new and experienced to machine learning as standard for image recognition. </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">To simplify the process of the deep learning workflow, we will be using NVIDIA's <span class="cm-link">[DIGITS]</span><span class="cm-string">(https://developer.nvidia.com/digits)</span>.  DIGITS is a Deep Learning GPU Training System that helps users develop and test convolutional neural networks. DIGITS supports multiple frameworks, data formats, and training goals including image classification and object detection.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In addition, DIGITS also includes a workload manager.  The workload manager allows the user to launch multiple jobs of different types and it coordinates access to the local resources.  If multiple GPUs are present, jobs can run simultaneously.  If more jobs are created than the resources available, the jobs will be queued until resources become free.  The DIGITS dashboard allows the user to monitor all of the active jobs and their current state.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">We will be using the <span class="cm-link">[Caffe]</span><span class="cm-string">(http://caffe.berkelyvision.org)</span> framework.  Caffe was created by the Berkeley Vision and Learning Center (BLVC).  Caffe is a flexible and extensible framework that provides researchers the means to train networks without writing all of the code necessary to do so.  Model training can be parallelized across multiple GPUs to accelerate learning.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">This tutorial will cover the typical tasks of the deep learning workflow.  First, we will create a database from the MNIST data.  Second, we will train a model to classify the MNIST images.  Third, we will test the trained model against other test data and analyze the results.  After this, we will augment the data and modify the standard network to try and improve our image classification accuracy.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 847px;"></div><div class="CodeMirror-gutters" style="display: none; height: 862px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Introduction-to-Deep-Learning">Introduction to Deep Learning<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Introduction-to-Deep-Learning">¶</a></h2>
<p>Deep learning is the use of many hidden layers in an artificial neural network to train a model to learn and understand the data without an inherent understanding of what the data are.  deep learning is being used by many different disciplines to allow computers to learn from vast amounts of data.  Recent advances in computer vision, object detection and natural language processing can be attributed to the adoption of Deep Learning techniques.</p>
<p>One key to the success of deep learning is the convolutional neural network (CNN).  In a traditional neural network, a artificial neurons in a layer are fully connected to the previous and next layer.  In a <a href="http://en.wikipedia.org/wiki/Convolutional_neural_network" target="_blank">convolutional neural network</a>, overlapping regions of the network are associated instead of the entire layer.  Biologically inspired, a convolutional network acts as filters to process pieces of data.  The result is that these networks can act as feature extractors at both coarse and fine scales eliminating the need to design custom feature extractors as was done previously in traditional computer vision.  CNNs can be trained to recognize structure in large sets of data including images, voice, and text.   </p>
<p>The workflow of deep learning is a multi-phase, iterative process.  First, data must be gathered and pre-processed.  While the Internet and big data have provide access to massive quantities of data, the data often need to be verified, labeled, and pre-processed for consistency.  Second, the data are used to train a network.  Pre-existing networks can be used or new ones can be developed.  Both the network and the training process have many variables that can be modified and tuned which affect the training rate and accuracy.  Third, models need to be tested to verify they are working as expected.  Often at this point one iteriates over the steps to improve the results.  This includes Reprocessing data, modifying networks, modifying parameters of the networks or solvers, and retesting until the desired results are obtained.</p>
<p>In this tutorial today, you will work through all phases of the deep learning workflow to solve a classic machine learning problem, text recognition.  We will be using a multi-layer convolutional neural network to train our model to recognize handwritten digits from the [MNIST] (<a href="http://yann.lecun.com/exdb/mnist/" target="_blank">http://yann.lecun.com/exdb/mnist/</a>) database. The MNIST database contains thousands of images of handwritten numbers from 0 to 9.  This dataset has been used by both those new and experienced to machine learning as standard for image recognition. </p>
<p>To simplify the process of the deep learning workflow, we will be using NVIDIA's <a href="https://developer.nvidia.com/digits" target="_blank">DIGITS</a>.  DIGITS is a Deep Learning GPU Training System that helps users develop and test convolutional neural networks. DIGITS supports multiple frameworks, data formats, and training goals including image classification and object detection.</p>
<p>In addition, DIGITS also includes a workload manager.  The workload manager allows the user to launch multiple jobs of different types and it coordinates access to the local resources.  If multiple GPUs are present, jobs can run simultaneously.  If more jobs are created than the resources available, the jobs will be queued until resources become free.  The DIGITS dashboard allows the user to monitor all of the active jobs and their current state.</p>
<p>We will be using the <a href="http://caffe.berkelyvision.org/" target="_blank">Caffe</a> framework.  Caffe was created by the Berkeley Vision and Learning Center (BLVC).  Caffe is a flexible and extensible framework that provides researchers the means to train networks without writing all of the code necessary to do so.  Model training can be parallelized across multiple GPUs to accelerate learning.</p>
<p>This tutorial will cover the typical tasks of the deep learning workflow.  First, we will create a database from the MNIST data.  Second, we will train a model to classify the MNIST images.  Third, we will test the trained model against other test data and analyze the results.  After this, we will augment the data and modify the standard network to try and improve our image classification accuracy.</p>
</div></div></div><div class="cell text_cell rendered unselected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 371px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Starting DIGITS</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">When you start DIGITS, you will be taken to the home screen.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_home.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">You can create new datasets or new models.  This home page will show all of your currently processing and completed models and datasets.  The default window pane shows the models.  If you wish to look at the datasets, select the <span class="cm-strong">**Datasets**</span> tab on the left.  On the right there are two tabs <span class="cm-strong">**New Datasets**</span> and <span class="cm-strong">**New Models**</span>.  Select the tab you wish to create a new dataset or net model.  When you do, you will be presented a menu of choices.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_zoom_new_dataset.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">You can choose either <span class="cm-strong">**Classification**</span>, <span class="cm-strong">**Object Detection**</span> or <span class="cm-strong">**Other**</span>.  In this tutorial, we will be using the <span class="cm-strong">**Classification**</span> option.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">When creating a new model, you will get a similar drop down menu.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_zoom_new_model.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">To start DIGITS, <span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">a</span> <span class="cm-attribute">href</span>=<span class="cm-string">"/digits/"</span> <span class="cm-attribute">target</span>=<span class="cm-string">"_blank"</span><span class="cm-tag cm-bracket">&gt;</span>click here<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">a</span><span class="cm-tag cm-bracket">&gt;</span>.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 371px;"></div><div class="CodeMirror-gutters" style="display: none; height: 386px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Starting-DIGITS">Starting DIGITS<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Starting-DIGITS">¶</a></h2>
<p>When you start DIGITS, you will be taken to the home screen.  </p>
<p><img src="./Getting Started with Deep Learning_files/digits_home.png" alt=""></p>
<p>You can create new datasets or new models.  This home page will show all of your currently processing and completed models and datasets.  The default window pane shows the models.  If you wish to look at the datasets, select the <strong>Datasets</strong> tab on the left.  On the right there are two tabs <strong>New Datasets</strong> and <strong>New Models</strong>.  Select the tab you wish to create a new dataset or net model.  When you do, you will be presented a menu of choices.</p>
<p><img src="./Getting Started with Deep Learning_files/digits_zoom_new_dataset.png" alt=""></p>
<p>You can choose either <strong>Classification</strong>, <strong>Object Detection</strong> or <strong>Other</strong>.  In this tutorial, we will be using the <strong>Classification</strong> option.  </p>
<p>When creating a new model, you will get a similar drop down menu.</p>
<p><img src="./Getting Started with Deep Learning_files/digits_zoom_new_model.png" alt=""></p>
<p>To start DIGITS, <a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/digits/" target="_blank">click here</a>.</p>
</div></div></div><div class="cell text_cell rendered unselected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 609px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Task - Create a Database</span></span></pre><pre class=""><span style="padding-right: 0.1px;">First, we want to create a database from the MNIST data. To create a database, select <span class="cm-strong">**Classification**</span> from the <span class="cm-strong">**New Dataset**</span> menu. &nbsp;  At this point you may need to enter a username.  If requested, just enter any name in lower-case.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In the <span class="cm-strong">**New Dataset**</span> window, you want to set the following fields to the values specified:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Image Type : Grayscale</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Image Size : 28 x 28</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Training Images: /home/ubuntu/data/train_small</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Select </span><span class="cm-strong cm-variable-2">**Separate test images folder**</span><span class="cm-variable-2"> checkbox</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Test Images : /home/ubuntu/data/test_small</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Dataset Name : MNIST Small</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Your screen should look like the image below.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_new_classification_dataset.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">When you have filled in the fields, press the <span class="cm-strong">**Create**</span> button.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The next window will show you the progress of the job and the estimated time to completion.  This shouldn't take more than a minute.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">When it is done, you can explore the database.  Find the <span class="cm-strong">**Explore**</span> Button at the bottom of the <span class="cm-strong">**Create DB (train)**</span> panel.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_explore_db.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Here you can scan through all of the images in the database. When the database is created, the image order is randomized. Models will train faster and more accuractely when they do not process the images in order (process all of the images of zeros, then all of the images of ones, etc.). When you explore your database, your database will be in a different order than the one shown here. </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">On this page you can see several examples of the handwritten digits.  Some are neat, some are sloppy, but all are different.  We want our system to be able to properly classify each variant.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 609px;"></div><div class="CodeMirror-gutters" style="display: none; height: 624px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Task---Create-a-Database">Task - Create a Database<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Task---Create-a-Database">¶</a></h2>
<p>First, we want to create a database from the MNIST data. To create a database, select <strong>Classification</strong> from the <strong>New Dataset</strong> menu.    At this point you may need to enter a username.  If requested, just enter any name in lower-case.</p>
<p>In the <strong>New Dataset</strong> window, you want to set the following fields to the values specified:</p>
<ul>
<li>Image Type : Grayscale</li>
<li>Image Size : 28 x 28</li>
<li>Training Images: /home/ubuntu/data/train_small</li>
<li>Select <strong>Separate test images folder</strong> checkbox</li>
<li>Test Images : /home/ubuntu/data/test_small</li>
<li>Dataset Name : MNIST Small</li>
</ul>
<p>Your screen should look like the image below.</p>
<p><img src="./Getting Started with Deep Learning_files/digits_new_classification_dataset.png" alt=""></p>
<p>When you have filled in the fields, press the <strong>Create</strong> button.</p>
<p>The next window will show you the progress of the job and the estimated time to completion.  This shouldn't take more than a minute.</p>
<p>When it is done, you can explore the database.  Find the <strong>Explore</strong> Button at the bottom of the <strong>Create DB (train)</strong> panel.  </p>
<p><img src="./Getting Started with Deep Learning_files/digits_explore_db.png" alt=""></p>
<p>Here you can scan through all of the images in the database. When the database is created, the image order is randomized. Models will train faster and more accuractely when they do not process the images in order (process all of the images of zeros, then all of the images of ones, etc.). When you explore your database, your database will be in a different order than the one shown here. </p>
<p>On this page you can see several examples of the handwritten digits.  Some are neat, some are sloppy, but all are different.  We want our system to be able to properly classify each variant.</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 1017px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Task 2 - Create the Model</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now that we have a database of images, lets train our network.  At the top right of every page, the name of our training system, <span class="cm-strong">**DIGITS**</span>, is visible.  If you click the name it will take you back to your home page.  From here, we can select <span class="cm-strong">**Classification**</span> from the <span class="cm-strong">**New Model**</span> menu.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In the <span class="cm-strong">**New Image Classification Model**</span> page, there are many options available to configure and tune your training session.  Some of the more typically used ones are:<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-strong cm-variable-2">**Select Dataset**</span><span class="cm-variable-2"> - Choose one of your databases to use for training.</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-strong cm-variable-2">**Training Epochs**</span><span class="cm-variable-2"> - Select the number of epochs for training.  An epoch is one iteration through the training data.  The number of epochs to use depends on the data and the model, but can be as few as 5 or over 100.</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-strong cm-variable-2">**Snapshot Interval**</span><span class="cm-variable-2"> - The frequency, in epochs, that the model state is saved to a file.</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-strong cm-variable-2">**Validation Interval**</span><span class="cm-variable-2"> - The frequency, in epochs, that the accuracy of the model is computed against the validation data.  This is important so you can monitor the progress of your training sessions.</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-strong cm-variable-2">**Random Seed**</span><span class="cm-variable-2"> - Specifies the value of seed should be used by the random number generator.  By setting this value, then the initial model will be randomize to the same state for different training sessions.</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-strong cm-variable-2">**Batch Size**</span><span class="cm-variable-2"> - The batch size is the number of images to use at one time.  The larger the batch size, the more parallelism that can be acheived and the faster the training will progress.  The batch size will be constrained by the size of available memory in your GPU.  You typically want to use the largest value possible.</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- </span><span class="cm-strong cm-variable-2">**Base Learning Rate**</span><span class="cm-variable-2"> - This value specifies at what rate the network will learn. The weights of the model are found using some gradient descent method.  The value describes the size of the step to be taken for each iteration.  Too large of a value and the weights will change to quickly and the model may not converge.  Too small of a value and the solution will take longer to converge. </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">DIGITS currently has built-in support for three networks.  <span class="cm-link">[LeNet]</span><span class="cm-string">(http://yann.lecun.com/exdb/lenet/)</span> is a convolutional network originally developed to recognize hand written digits. In 2012 <span class="cm-link">[AlexNet]</span><span class="cm-string">(http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)</span> won the <span class="cm-link">[ImageNet]</span><span class="cm-string">(http://image-net.org/)</span> compitition using a Deep Neural network instead of traditional computer vision techniques. This revolutionized the field of computer vision and within a couple of years all of the top entries in the ImageNet competition were based on Deep Neural Netowrks.  <span class="cm-link">[GoogleNet]</span><span class="cm-string">(https://arxiv.org/abs/1409.4842)</span> in 2014 set a new standard of image classification in the ImageNet competition.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">DIGITS also supports two frameworks.  Caffe is the one with which we will be working today.  Torch (<span class="cm-link">http://torch.ch/</span>) is another framework that is good at image classification as well as speech recognition and language processing and.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">To train our model, we want to set the following options:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Select the </span><span class="cm-strong cm-variable-2">**MNIST small**</span><span class="cm-variable-2"> dataset</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set the number of </span><span class="cm-strong cm-variable-2">**Training Epochs**</span><span class="cm-variable-2"> to 10</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set the framework to </span><span class="cm-strong cm-variable-2">**Caffe**</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set the model to </span><span class="cm-strong cm-variable-2">**LeNet**</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Set the name of the model to </span><span class="cm-strong cm-variable-2">**MNIST small**</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_create_new_model.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">When you have set all of these options, press the Create button.  You are now training your model!  For this configuration, the model training should complete in less than a minute.  While the training progresses, the statistics of the model are updated in the window.  The chart in the middle provides key information to how well your training is doing.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_model_loss_accuracy.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Three quantities are reported training loss, validation loss, and accuracy.  The values of training and validation loss should decrease from epoch to epoch, although they may jump around some.  The accuracy is the measure of the ability of the model to correctly classify the validation data.  If you hover your mouse over any of the data points, you will see its exact value.  In this case, the accuracy at the last epoch is about 96%.  Your results might be slightly different that what is shown here since the initial networks are generated randomly.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">An accuracy of 96% sounds pretty good for a model that finished in seconds!  But does it work in practice?</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 1017px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1032px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Task-2---Create-the-Model">Task 2 - Create the Model<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Task-2---Create-the-Model">¶</a></h2>
<p>Now that we have a database of images, lets train our network.  At the top right of every page, the name of our training system, <strong>DIGITS</strong>, is visible.  If you click the name it will take you back to your home page.  From here, we can select <strong>Classification</strong> from the <strong>New Model</strong> menu.  </p>
<p>In the <strong>New Image Classification Model</strong> page, there are many options available to configure and tune your training session.  Some of the more typically used ones are:  </p>
<ul>
<li><strong>Select Dataset</strong> - Choose one of your databases to use for training.</li>
<li><strong>Training Epochs</strong> - Select the number of epochs for training.  An epoch is one iteration through the training data.  The number of epochs to use depends on the data and the model, but can be as few as 5 or over 100.</li>
<li><strong>Snapshot Interval</strong> - The frequency, in epochs, that the model state is saved to a file.</li>
<li><strong>Validation Interval</strong> - The frequency, in epochs, that the accuracy of the model is computed against the validation data.  This is important so you can monitor the progress of your training sessions.</li>
<li><strong>Random Seed</strong> - Specifies the value of seed should be used by the random number generator.  By setting this value, then the initial model will be randomize to the same state for different training sessions.</li>
<li><strong>Batch Size</strong> - The batch size is the number of images to use at one time.  The larger the batch size, the more parallelism that can be acheived and the faster the training will progress.  The batch size will be constrained by the size of available memory in your GPU.  You typically want to use the largest value possible.</li>
<li><strong>Base Learning Rate</strong> - This value specifies at what rate the network will learn. The weights of the model are found using some gradient descent method.  The value describes the size of the step to be taken for each iteration.  Too large of a value and the weights will change to quickly and the model may not converge.  Too small of a value and the solution will take longer to converge. </li>
</ul>
<p>DIGITS currently has built-in support for three networks.  <a href="http://yann.lecun.com/exdb/lenet/" target="_blank">LeNet</a> is a convolutional network originally developed to recognize hand written digits. In 2012 <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf" target="_blank">AlexNet</a> won the <a href="http://image-net.org/" target="_blank">ImageNet</a> compitition using a Deep Neural network instead of traditional computer vision techniques. This revolutionized the field of computer vision and within a couple of years all of the top entries in the ImageNet competition were based on Deep Neural Netowrks.  <a href="https://arxiv.org/abs/1409.4842" target="_blank">GoogleNet</a> in 2014 set a new standard of image classification in the ImageNet competition.</p>
<p>DIGITS also supports two frameworks.  Caffe is the one with which we will be working today.  Torch (<a href="http://torch.ch/" target="_blank">http://torch.ch/</a>) is another framework that is good at image classification as well as speech recognition and language processing and.</p>
<p>To train our model, we want to set the following options:</p>
<ul>
<li>Select the <strong>MNIST small</strong> dataset</li>
<li>Set the number of <strong>Training Epochs</strong> to 10</li>
<li>Set the framework to <strong>Caffe</strong></li>
<li>Set the model to <strong>LeNet</strong></li>
<li>Set the name of the model to <strong>MNIST small</strong></li>
</ul>
<p><img src="./Getting Started with Deep Learning_files/digits_create_new_model.png" alt=""></p>
<p>When you have set all of these options, press the Create button.  You are now training your model!  For this configuration, the model training should complete in less than a minute.  While the training progresses, the statistics of the model are updated in the window.  The chart in the middle provides key information to how well your training is doing.</p>
<p><img src="./Getting Started with Deep Learning_files/digits_model_loss_accuracy.png" alt=""></p>
<p>Three quantities are reported training loss, validation loss, and accuracy.  The values of training and validation loss should decrease from epoch to epoch, although they may jump around some.  The accuracy is the measure of the ability of the model to correctly classify the validation data.  If you hover your mouse over any of the data points, you will see its exact value.  In this case, the accuracy at the last epoch is about 96%.  Your results might be slightly different that what is shown here since the initial networks are generated randomly.</p>
<p>An accuracy of 96% sounds pretty good for a model that finished in seconds!  But does it work in practice?</p>
</div></div></div><div class="cell text_cell rendered unselected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 914px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 19px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-3">### Test The Model</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Lets test the ability of the model to identify other images.  If you go to the bottom of the window, you can test a single image or a list of images.  On the left, type in the path <span class="cm-strong">**/home/ubuntu/data/test_small/2/img_4415.png**</span> in the Image Path text box.  Select the <span class="cm-strong">**Show visualizations and statistics**</span> checkbox, then select the <span class="cm-strong">**Classify One**</span> button.  After a few seconds, a new window is displayed with the image and information about its attempt to classify the image.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_classify_one_1.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_classify_one_2.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The figure above show the top portion of what you will see in your window.  The data in this window provides information about how well the model is doing but it also provides information regarding what each of the layers is doing. You can see that the model reported that there is a 95.8% chance that your image contained a 2.  It got it right.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In the LeNet network, the first few layers scale the data.  The scaled and data layers show how the original image is scaled and what the resulting image looks like.  The conv1 layer used a 5x5 kernel and 20 outputs.  You can see that in the conv1 Weights section there are 20 5x5 images.  Each of these these kernels has learned something about the low level features of the images.  Since the kernel is 5x5, as it slides across the 28x28 image, the output from the convolution is 24x24.  This is reported in the conv1 Activiation section where the data output is reported as <span class="cm-strong">**[20 24 24]**</span>.  As data are processed through the CNN, the images continue to get smaller which allows the network to detect different features.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The pool1 layer has a kernel size of 2, a stride of 2, and is set to MAX.  This means it returns the maximum value within a 2x2 patch, skipping 2 pixels as it moves across the image.  The image size input to this layer was 24x24, and the resulting image size is 12x12.  You can continue to work through all of the layers and see how the data are learned by the output from the Activation sections and how the images are transformed as they progress through the network.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">At the bottom of this page (not shown here), the statistics page reports the <span class="cm-strong">**Total Learned Parameters**</span> as 431,080.  This might sound like a large number of weights, but it is quite small compared to other networks.  Networks like AlexNet and GoogleNet have tens of millions or hundreds of millions of weights.  There are even networks that have more than a billion weights.  As our images are only 28x28, we would not have enough information in our data to train networks of those sizes.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Lets try testing the model with a set of images.  They are shown below.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"test_images/image-1-1.jpg"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"64px"</span> <span class="cm-tag cm-bracket">/&gt;</span> <span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">div</span> <span class="cm-attribute">style</span>=<span class="cm-string">"</span><span class="cm-string cm-link">text-align:center</span><span class="cm-string">;"</span><span class="cm-tag cm-bracket">&gt;</span>image-1-1.jpg<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">div</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"test_images/image-2-1.jpg"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"64px"</span> <span class="cm-tag cm-bracket">/&gt;</span> <span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">div</span> <span class="cm-attribute">style</span>=<span class="cm-string">"</span><span class="cm-string cm-link">text-align:center</span><span class="cm-string">;"</span><span class="cm-tag cm-bracket">&gt;</span>image-2-1.jpg<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">div</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"test_images/image-3-1.jpg"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"64px"</span> <span class="cm-tag cm-bracket">/&gt;</span> <span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">div</span> <span class="cm-attribute">style</span>=<span class="cm-string">"</span><span class="cm-string cm-link">text-align:center</span><span class="cm-string">;"</span><span class="cm-tag cm-bracket">&gt;</span>image-3-1.jpg<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">div</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"test_images/image-4-1.jpg"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"64px"</span> <span class="cm-tag cm-bracket">/&gt;</span> <span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">div</span> <span class="cm-attribute">style</span>=<span class="cm-string">"</span><span class="cm-string cm-link">text-align:center</span><span class="cm-string">;"</span><span class="cm-tag cm-bracket">&gt;</span>image-4-1.jpg<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">div</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"test_images/image-7-1.jpg"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"64px"</span> <span class="cm-tag cm-bracket">/&gt;</span> <span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">div</span> <span class="cm-attribute">style</span>=<span class="cm-string">"</span><span class="cm-string cm-link">text-align:center</span><span class="cm-string">;"</span><span class="cm-tag cm-bracket">&gt;</span>image-7-1.jpg<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">div</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"test_images/image-8-1.jpg"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"64px"</span> <span class="cm-tag cm-bracket">/&gt;</span> <span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">div</span> <span class="cm-attribute">style</span>=<span class="cm-string">"</span><span class="cm-string cm-link">text-align:center</span><span class="cm-string">;"</span><span class="cm-tag cm-bracket">&gt;</span>image-8-1.jpg<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">div</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">img</span> <span class="cm-attribute">src</span>=<span class="cm-string">"test_images/image-8-2.jpg"</span> <span class="cm-attribute">width</span>=<span class="cm-string">"64px"</span> <span class="cm-tag cm-bracket">/&gt;</span> <span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">div</span> <span class="cm-attribute">style</span>=<span class="cm-string">"</span><span class="cm-string cm-link">text-align:center</span><span class="cm-string">;"</span><span class="cm-tag cm-bracket">&gt;</span>image-8-2.jpg<span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">div</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">While these are clearly numbers to us humans, they look different from the images that we inspected earlier.  Some have color, some have backgrounds, and very few look like hand written digits.  How does our model do against these images?</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">We can classify multiple files if we put them in the list. In the link below, execute the code block and a link to the file an_image.list will appear.  Right click on an_image.list and save that to a file on your local computer. Remember the directory in which it is saved.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 914px;"></div><div class="CodeMirror-gutters" style="display: none; height: 929px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h3 id="Test-The-Model">Test The Model<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Test-The-Model">¶</a></h3>
<p>Lets test the ability of the model to identify other images.  If you go to the bottom of the window, you can test a single image or a list of images.  On the left, type in the path <strong>/home/ubuntu/data/test_small/2/img_4415.png</strong> in the Image Path text box.  Select the <strong>Show visualizations and statistics</strong> checkbox, then select the <strong>Classify One</strong> button.  After a few seconds, a new window is displayed with the image and information about its attempt to classify the image.</p>
<p><img src="./Getting Started with Deep Learning_files/digits_classify_one_1.png" alt="">
<img src="./Getting Started with Deep Learning_files/digits_classify_one_2.png" alt=""></p>
<p>The figure above show the top portion of what you will see in your window.  The data in this window provides information about how well the model is doing but it also provides information regarding what each of the layers is doing. You can see that the model reported that there is a 95.8% chance that your image contained a 2.  It got it right.  </p>
<p>In the LeNet network, the first few layers scale the data.  The scaled and data layers show how the original image is scaled and what the resulting image looks like.  The conv1 layer used a 5x5 kernel and 20 outputs.  You can see that in the conv1 Weights section there are 20 5x5 images.  Each of these these kernels has learned something about the low level features of the images.  Since the kernel is 5x5, as it slides across the 28x28 image, the output from the convolution is 24x24.  This is reported in the conv1 Activiation section where the data output is reported as <strong>[20 24 24]</strong>.  As data are processed through the CNN, the images continue to get smaller which allows the network to detect different features.  </p>
<p>The pool1 layer has a kernel size of 2, a stride of 2, and is set to MAX.  This means it returns the maximum value within a 2x2 patch, skipping 2 pixels as it moves across the image.  The image size input to this layer was 24x24, and the resulting image size is 12x12.  You can continue to work through all of the layers and see how the data are learned by the output from the Activation sections and how the images are transformed as they progress through the network.</p>
<p>At the bottom of this page (not shown here), the statistics page reports the <strong>Total Learned Parameters</strong> as 431,080.  This might sound like a large number of weights, but it is quite small compared to other networks.  Networks like AlexNet and GoogleNet have tens of millions or hundreds of millions of weights.  There are even networks that have more than a billion weights.  As our images are only 28x28, we would not have enough information in our data to train networks of those sizes.</p>
<p>Lets try testing the model with a set of images.  They are shown below.</p>
<p><img src="./Getting Started with Deep Learning_files/image-1-1.jpg" width="64px"> </p><div style="text-align:center;">image-1-1.jpg</div>
<img src="./Getting Started with Deep Learning_files/image-2-1.jpg" width="64px"> <div style="text-align:center;">image-2-1.jpg</div>
<img src="./Getting Started with Deep Learning_files/image-3-1.jpg" width="64px"> <div style="text-align:center;">image-3-1.jpg</div>
<img src="./Getting Started with Deep Learning_files/image-4-1.jpg" width="64px"> <div style="text-align:center;">image-4-1.jpg</div>
<img src="./Getting Started with Deep Learning_files/image-7-1.jpg" width="64px"> <div style="text-align:center;">image-7-1.jpg</div>
<img src="./Getting Started with Deep Learning_files/image-8-1.jpg" width="64px"> <div style="text-align:center;">image-8-1.jpg</div>
<img src="./Getting Started with Deep Learning_files/image-8-2.jpg" width="64px"> <div style="text-align:center;">image-8-2.jpg</div><p></p>
<p>While these are clearly numbers to us humans, they look different from the images that we inspected earlier.  Some have color, some have backgrounds, and very few look like hand written digits.  How does our model do against these images?</p>
<p>We can classify multiple files if we put them in the list. In the link below, execute the code block and a link to the file an_image.list will appear.  Right click on an_image.list and save that to a file on your local computer. Remember the directory in which it is saved.</p>
</div></div></div><div class="cell code_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="input"><div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-ipython"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; min-width: 397.766px; margin-bottom: -15px; border-right-width: 15px; min-height: 45px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 17px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">IPython</span>.<span class="cm-variable">display</span> <span class="cm-keyword">import</span> <span class="cm-variable">FileLink</span>, <span class="cm-variable">FileLinks</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable">FileLinks</span>(<span class="cm-string">'test_images_list'</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 45px;"></div><div class="CodeMirror-gutters" style="display: none; height: 60px;"></div></div></div></div></div></div><div class="widget-area" style="display: none;"><div class="prompt"><button class="close" data-vivaldi-spatnav-clickable="1">×</button></div><div class="widget-subarea"></div></div><div class="output_wrapper"><div class="out_prompt_overlay prompt" title="click to expand output; double click to hide output" data-vivaldi-spatnav-clickable="1" style=""></div><div class="output" style=""></div><div class="btn btn-default output_collapsed" title="click to expand output" data-vivaldi-spatnav-clickable="1" style="display: none;">. . .</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 215px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 16.5px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;">On the right side of the DIGITS, there is an option to specify an Image List file.  Press the button <span class="cm-strong">**Choose File**</span> and select the <span class="cm-comment">`an_image.list`</span> file you just downloaded. The press the <span class="cm-strong">**Classify Many**</span> button.  After several seconds, you will see the results from Caffe trying to classify these images with the generated model.  In the image name, the first number is the digit in the image (ex. image-3-1.jpg is a 3). Your results should be similar to this:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/classify-many-images-small.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">What is shown here is the probabilty that the model predicts the class of the image.  The results are sorted from highest probability to lowest.  All but the last two of these predictions are incorrect.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">While the accuracy of the model was 96%, it could not correctly classify any of the images that we tested.  What can we do to improve the classification of these images?</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 215px;"></div><div class="CodeMirror-gutters" style="display: none; height: 230px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><p>On the right side of the DIGITS, there is an option to specify an Image List file.  Press the button <strong>Choose File</strong> and select the <code>an_image.list</code> file you just downloaded. The press the <strong>Classify Many</strong> button.  After several seconds, you will see the results from Caffe trying to classify these images with the generated model.  In the image name, the first number is the digit in the image (ex. image-3-1.jpg is a 3). Your results should be similar to this:</p>
<p><img src="./Getting Started with Deep Learning_files/classify-many-images-small.png" alt=""></p>
<p>What is shown here is the probabilty that the model predicts the class of the image.  The results are sorted from highest probability to lowest.  All but the last two of these predictions are incorrect.</p>
<p>While the accuracy of the model was 96%, it could not correctly classify any of the images that we tested.  What can we do to improve the classification of these images?</p>
</div></div></div><div class="cell text_cell rendered unselected" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 779px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Train with more data</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In our first attempt at training, we only used 10% of the full MNIST dataset.  Lets try training with the complete dataset and see how it improves our training.  We can use the clone option in DIGITS to simplify the creation of a new job with similar properties as an older job.  Lets return to the home page by clicking on <span class="cm-strong">**DIGITS**</span> in the upper left hand corner.  Then select <span class="cm-strong">**Dataset**</span> from the left side of the page to see all of the datasets that you have created.  You will see your <span class="cm-strong">**MNIST small**</span> dataset.  When you select that dataset, you will be returned to the results window of that job.  In the right hand corner you will see a button <span class="cm-strong">**Clone Job**</span>. </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_clone_dataset.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Press the <span class="cm-strong">**Clone Job**</span> button.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-new-line"> </span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">From here you will see the create dataset template populated with all the options you used when you created the MNIST small dataset.  To create a database with the full MNIST data, change the following settings:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Training Images - /home/ubuntu/data/train_full</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Test Image - /home/ubuntu/data/test_full</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Dataset Name - MNIST full</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Then press the <span class="cm-strong">**Create**</span> button.  This dataset is ten times larger than the other dataset, so it will take a few minutes to process.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">After you have created your new database, follow the same procedure to clone your training model.  In the template, change the following values:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Select the MNIST full dataset</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Change the name to MNIST full</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Then create the model.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">With six times more data the model will take longer to run. It still should complete in less than a minute.  What do you notice different about the results?  Both the training and validation loss function values are much smaller.  In addition, the accuracy of the model is around 99%, possibly greater. That is saying correctly identifying most every image in its validation set.  This is an large improvement.  However, how well does this new model do on the test images we used previously?</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Using the same procedure from above to classify our set of test images, here are the new results:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_classify_many_full.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The model was still only able to classify two of the seven images.  While some of the classifications came in a close second, our model's predictive capabilities were not much greater.  So are we asking too much of this model to try and classify non-handwritten, often colored, digits with our model? </span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 779px;"></div><div class="CodeMirror-gutters" style="display: none; height: 794px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Train-with-more-data">Train with more data<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Train-with-more-data">¶</a></h2>
<p>In our first attempt at training, we only used 10% of the full MNIST dataset.  Lets try training with the complete dataset and see how it improves our training.  We can use the clone option in DIGITS to simplify the creation of a new job with similar properties as an older job.  Lets return to the home page by clicking on <strong>DIGITS</strong> in the upper left hand corner.  Then select <strong>Dataset</strong> from the left side of the page to see all of the datasets that you have created.  You will see your <strong>MNIST small</strong> dataset.  When you select that dataset, you will be returned to the results window of that job.  In the right hand corner you will see a button <strong>Clone Job</strong>. </p>
<p><img src="./Getting Started with Deep Learning_files/digits_clone_dataset.png" alt=""></p>
<p>Press the <strong>Clone Job</strong> button.  </p>
<p>From here you will see the create dataset template populated with all the options you used when you created the MNIST small dataset.  To create a database with the full MNIST data, change the following settings:</p>
<ul>
<li>Training Images - /home/ubuntu/data/train_full</li>
<li>Test Image - /home/ubuntu/data/test_full</li>
<li>Dataset Name - MNIST full</li>
</ul>
<p>Then press the <strong>Create</strong> button.  This dataset is ten times larger than the other dataset, so it will take a few minutes to process.</p>
<p>After you have created your new database, follow the same procedure to clone your training model.  In the template, change the following values:</p>
<ul>
<li>Select the MNIST full dataset</li>
<li>Change the name to MNIST full</li>
</ul>
<p>Then create the model.</p>
<p>With six times more data the model will take longer to run. It still should complete in less than a minute.  What do you notice different about the results?  Both the training and validation loss function values are much smaller.  In addition, the accuracy of the model is around 99%, possibly greater. That is saying correctly identifying most every image in its validation set.  This is an large improvement.  However, how well does this new model do on the test images we used previously?</p>
<p>Using the same procedure from above to classify our set of test images, here are the new results:</p>
<p><img src="./Getting Started with Deep Learning_files/digits_classify_many_full.png" alt=""></p>
<p>The model was still only able to classify two of the seven images.  While some of the classifications came in a close second, our model's predictive capabilities were not much greater.  So are we asking too much of this model to try and classify non-handwritten, often colored, digits with our model? </p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 507px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Improving Model Results - Data Augmentation</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">You can see with our seven test images that the backgrounds are not uniform.  In addition, most of the backgrounds are light in color whereas our training data all have black backgrounds. &nbsp; We saw that increasing the amount of data did help for classifying the hand-written characters, so what if we include more data that tries to address the contrast differences?</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Lets try augmenting our data by inverting the original images.  Lets turn the white pixels to black and vise-versa.  Then we will train our network using the original and inverted images and see if classification is improved.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">To do this, follow the steps above to clone and create a new dataset and model.  The directories for the augmented data are:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Training Images - /home/ubuntu/data/train_invert</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-variable-2">- Test Image - /home/ubuntu/data/test_invert</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Remember to change the name of your dataset and model.  When the new dataset is ready, explore the database.  Now you should see images with black backgrounds and white numbers and also white backgrounds and black numbers.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now train a new model.  Clone your previous model results, and change the dataset to the one you just created with the inverted images.  Change the name of the model and create a new model.  When the training is complete, the accuracy hasn't really increased over the non-augmented image set.  In fact, the accuracy may have gone down slightly.  We were already at 99% so it is unlikely we were going to improve our accuracy.  Did using an augmented dataset help us to better classify our images?  Here is the result:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/digits_classify_many_invert.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">By augmenting our dataset with the inverted images, we were able to identify four of the seven images.  While our results is not perfect, our small change to the images to increase our dataset size made a significant difference.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 507px;"></div><div class="CodeMirror-gutters" style="display: none; height: 522px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Improving-Model-Results---Data-Augmentation">Improving Model Results - Data Augmentation<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Improving-Model-Results---Data-Augmentation">¶</a></h2>
<p>You can see with our seven test images that the backgrounds are not uniform.  In addition, most of the backgrounds are light in color whereas our training data all have black backgrounds.   We saw that increasing the amount of data did help for classifying the hand-written characters, so what if we include more data that tries to address the contrast differences?</p>
<p>Lets try augmenting our data by inverting the original images.  Lets turn the white pixels to black and vise-versa.  Then we will train our network using the original and inverted images and see if classification is improved.</p>
<p>To do this, follow the steps above to clone and create a new dataset and model.  The directories for the augmented data are:</p>
<ul>
<li>Training Images - /home/ubuntu/data/train_invert</li>
<li>Test Image - /home/ubuntu/data/test_invert</li>
</ul>
<p>Remember to change the name of your dataset and model.  When the new dataset is ready, explore the database.  Now you should see images with black backgrounds and white numbers and also white backgrounds and black numbers.</p>
<p>Now train a new model.  Clone your previous model results, and change the dataset to the one you just created with the inverted images.  Change the name of the model and create a new model.  When the training is complete, the accuracy hasn't really increased over the non-augmented image set.  In fact, the accuracy may have gone down slightly.  We were already at 99% so it is unlikely we were going to improve our accuracy.  Did using an augmented dataset help us to better classify our images?  Here is the result:</p>
<p><img src="./Getting Started with Deep Learning_files/digits_classify_many_invert.png" alt=""></p>
<p>By augmenting our dataset with the inverted images, we were able to identify four of the seven images.  While our results is not perfect, our small change to the images to increase our dataset size made a significant difference.</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 1221px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Improving Model Results -- Modify the Network</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Augmenting the dataset improved our results, but we are not identifying all of our test images.  Lets try modifying the LeNet network directly.  You can create custom networks to modifying the existing ones, use different networks from external sources or create your one.  To modify a network, select the <span class="cm-em">*Customize*</span> link on the right side of the Network dialog box.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/network-dialog.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">This will open a editor with the LeNet model configuration.  Scroll through the window and look at the code.  The network is defined as a series of layers.  Each layer has a name that is a descriptor of its function.  Each layer has a top and a bottom, or possibly multiple of each, indicating how the layers are connected.  The <span class="cm-em">*type*</span> variable defined what type the layer is.  Possibilities include <span class="cm-strong">**Convolution**</span>, <span class="cm-strong">**Pool**</span>, and <span class="cm-strong">**ReLU**</span>.  All the options available in the Caffe model language are found in the <span class="cm-link">[Caffe Tutorial]</span><span class="cm-string">(http://caffe.berkeleyvision.org/tutorial/)</span>.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">At the top of the editor, there is a <span class="cm-strong">**Visualize**</span> button.  Pressing this button will visualize all of the layers of the model and how they are connected.  In this window, you can see that the data are initially scaled, there are two sets of Convolution and Pooling layers and two Inner Products with a Rectilinear Unit (ReLU) connected to the first Inner Product.  At the bottom of the network, there are output functions that return the accuracy and loss computed through the network.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">We are going to make two changes to the network.  First, we are going to connect a ReLU to the first pool.  Second, we are going to change the values of num_output to 75 for the first Convolution (conv1) and 100 for the second Convolution (conv2).  The ReLU layer definition should go below the pool1 definition and look like:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">code</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;">layer {</span></pre><pre class=""><span style="padding-right: 0.1px;">  name: "reluP1"</span></pre><pre class=""><span style="padding-right: 0.1px;">  type: "ReLU"</span></pre><pre class=""><span style="padding-right: 0.1px;">  bottom: "pool1"</span></pre><pre class=""><span style="padding-right: 0.1px;">  top: "pool1"</span></pre><pre class=""><span style="padding-right: 0.1px;">}</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">code</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">The Convolution layers should be changed to look like:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">code</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;">layer {</span></pre><pre class=""><span style="padding-right: 0.1px;">  name: "conv1"</span></pre><pre class=""><span style="padding-right: 0.1px;">  type: "Convolution"</span></pre><pre class=""><span style="padding-right: 0.1px;">  bottom: "scaled"</span></pre><pre class=""><span style="padding-right: 0.1px;">  top: "conv1"</span></pre><pre class=""><span style="padding-right: 0.1px;">...</span></pre><pre class=""><span style="padding-right: 0.1px;">  convolution_param {</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  num_output: **75**</span></pre><pre class=""><span style="padding-right: 0.1px;">...</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">code</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;</span><span class="cm-tag">code</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;">layer {</span></pre><pre class=""><span style="padding-right: 0.1px;">  name: "conv2"</span></pre><pre class=""><span style="padding-right: 0.1px;">  type: "Convolution"</span></pre><pre class=""><span style="padding-right: 0.1px;">  bottom: "pool1"</span></pre><pre class=""><span style="padding-right: 0.1px;">  top: "conv2"</span></pre><pre class=""><span style="padding-right: 0.1px;">...</span></pre><pre class=""><span style="padding-right: 0.1px;">  convolution_param {</span></pre><pre class=""><span style="padding-right: 0.1px;"> &nbsp;  num_output: **100**</span></pre><pre class=""><span style="padding-right: 0.1px;">...</span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag cm-bracket">&lt;/</span><span class="cm-tag">code</span><span class="cm-tag cm-bracket">&gt;</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Note, the ellipis (...) just indicates we removed some of the lines from the layer for brevity.  The only change you have to make is to the value of num_output.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">After making these changes, visualize your new model.  You should see the ReLU unit appear similar to:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/add-relu.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now change the name of the model and press the <span class="cm-strong">**Create**</span> button.  When it is complete test the data again.  The results should be similar to:</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span class="cm-tag">![]</span><span class="cm-string">(images/classify-invert-relu.png)</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Were you able to correctly identify them all? If not, why do you think the results were different?</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 1221px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1236px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Improving-Model-Results----Modify-the-Network">Improving Model Results -- Modify the Network<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Improving-Model-Results----Modify-the-Network">¶</a></h2>
<p>Augmenting the dataset improved our results, but we are not identifying all of our test images.  Lets try modifying the LeNet network directly.  You can create custom networks to modifying the existing ones, use different networks from external sources or create your one.  To modify a network, select the <em>Customize</em> link on the right side of the Network dialog box.</p>
<p><img src="./Getting Started with Deep Learning_files/network-dialog.png" alt=""></p>
<p>This will open a editor with the LeNet model configuration.  Scroll through the window and look at the code.  The network is defined as a series of layers.  Each layer has a name that is a descriptor of its function.  Each layer has a top and a bottom, or possibly multiple of each, indicating how the layers are connected.  The <em>type</em> variable defined what type the layer is.  Possibilities include <strong>Convolution</strong>, <strong>Pool</strong>, and <strong>ReLU</strong>.  All the options available in the Caffe model language are found in the <a href="http://caffe.berkeleyvision.org/tutorial/" target="_blank">Caffe Tutorial</a>.</p>
<p>At the top of the editor, there is a <strong>Visualize</strong> button.  Pressing this button will visualize all of the layers of the model and how they are connected.  In this window, you can see that the data are initially scaled, there are two sets of Convolution and Pooling layers and two Inner Products with a Rectilinear Unit (ReLU) connected to the first Inner Product.  At the bottom of the network, there are output functions that return the accuracy and loss computed through the network.</p>
<p>We are going to make two changes to the network.  First, we are going to connect a ReLU to the first pool.  Second, we are going to change the values of num_output to 75 for the first Convolution (conv1) and 100 for the second Convolution (conv2).  The ReLU layer definition should go below the pool1 definition and look like:</p>
<p><code>
layer {
  name: "reluP1"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
</code></p>
<p>The Convolution layers should be changed to look like:</p>
<p><code>
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "scaled"
  top: "conv1"
...
  convolution_param {
    num_output: <strong>75</strong>
...
</code>
<code>
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
...
  convolution_param {
    num_output: <strong>100</strong>
...
</code>
Note, the ellipis (...) just indicates we removed some of the lines from the layer for brevity.  The only change you have to make is to the value of num_output.</p>
<p>After making these changes, visualize your new model.  You should see the ReLU unit appear similar to:</p>
<p><img src="./Getting Started with Deep Learning_files/add-relu.png" alt=""></p>
<p>Now change the name of the model and press the <strong>Create</strong> button.  When it is complete test the data again.  The results should be similar to:</p>
<p><img src="./Getting Started with Deep Learning_files/classify-invert-relu.png" alt=""></p>
<p>Were you able to correctly identify them all? If not, why do you think the results were different?</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 133px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Next Steps</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In our example here, we were able to identify all of our test images successfully.  However that is generally not the case. &nbsp; How would be go about improving our model further?  Typically hyper-parameter searches are done to try different values of model parameters such as learning-rate or different solvers to find settings that improve model accuracy.  We could change the model to add layers or change some of the parameters within the model associated with the performance of the convolution and pooling layers.  In addition, we could try the other models, such as Alexnet.</span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 133px;"></div><div class="CodeMirror-gutters" style="display: none; height: 148px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Next-Steps">Next Steps<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Next-Steps">¶</a></h2>
<p>In our example here, we were able to identify all of our test images successfully.  However that is generally not the case.   How would be go about improving our model further?  Typically hyper-parameter searches are done to try different values of model parameters such as learning-rate or different solvers to find settings that improve model accuracy.  We could change the model to add layers or change some of the parameters within the model associated with the performance of the convolution and pooling layers.  In addition, we could try the other models, such as Alexnet.</p>
</div></div></div><div class="cell text_cell unselected rendered" tabindex="2" data-vivaldi-spatnav-clickable="1"><div class="prompt input_prompt"></div><div class="inner_cell"><div class="ctb_hideshow"><div class="celltoolbar"></div></div><div class="input_area"><div class="CodeMirror cm-s-default CodeMirror-wrap"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 5.59375px; left: 5.59375px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-vscrollbar" not-content="true" style="bottom: 0px;"><div style="min-width: 1px; height: 0px;"></div></div><div class="CodeMirror-hscrollbar" not-content="true"><div style="height: 100%; min-height: 1px; width: 0px;"></div></div><div class="CodeMirror-scrollbar-filler" not-content="true"></div><div class="CodeMirror-gutter-filler" not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; padding-right: 0px; padding-bottom: 0px; margin-bottom: -15px; border-right-width: 15px; min-height: 269px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines"><div style="position: relative; outline: none;"><div class="CodeMirror-measure"></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-cursors"><div class="CodeMirror-cursor" style="left: 0px; top: 0px; height: 20px;">&nbsp;</div></div><div class="CodeMirror-code"><pre class=""><span style="padding-right: 0.1px;"><span class="cm-header cm-header-2">## Summary</span></span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">In this tutorial you were provided an introduction to the Deep Learning and all of the steps necessary to classify images including data processing, training, testing, and improving your network through data augmentation and network modifications.  In the training phase, you learned about the parameters that can determine the performance of training a network. By training a subset of the MNIST data as well as the full set, we learned that the more data is better.  In testing our model, we found that although the test images were quite different than the training data, we could still correctly classify them.</span></pre><pre class=""><span style="padding-right: 0.1px;"><span>​</span></span></pre><pre class=""><span style="padding-right: 0.1px;">Now that you have a basic understanding of Deep Learning and how to train using both Caffe and Digits, what you do next is limited by only your own imagination.  To test what you have learned, there are several good datasets with which to practice.  First, there is the <span class="cm-link">[CIFAR]</span><span class="cm-string">(https://www.cs.toronto.edu/~kriz/cifar.html)</span> dataset.  The CIFAR is a set of 60000  small (32x32) images with numerous classes such as dogs, cats, planes, and trucks.  The CIFAR10 dataset has 10 different classes of data.  The CIFAR100 dataset is an extension with 100 different classes of data.  In addtion, the ImageNet database is another dataset with which to test your skills.<span class="cm-trailing-space-a"> </span><span class="cm-trailing-space-b"> </span><span class="cm-trailing-space-new-line"> </span></span></pre></div></div></div></div></div><div style="position: absolute; height: 15px; width: 1px; top: 269px;"></div><div class="CodeMirror-gutters" style="display: none; height: 284px;"></div></div></div></div><div class="text_cell_render rendered_html" tabindex="-1"><h2 id="Summary">Summary<a class="anchor-link" href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#Summary">¶</a></h2>
<p>In this tutorial you were provided an introduction to the Deep Learning and all of the steps necessary to classify images including data processing, training, testing, and improving your network through data augmentation and network modifications.  In the training phase, you learned about the parameters that can determine the performance of training a network. By training a subset of the MNIST data as well as the full set, we learned that the more data is better.  In testing our model, we found that although the test images were quite different than the training data, we could still correctly classify them.</p>
<p>Now that you have a basic understanding of Deep Learning and how to train using both Caffe and Digits, what you do next is limited by only your own imagination.  To test what you have learned, there are several good datasets with which to practice.  First, there is the <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">CIFAR</a> dataset.  The CIFAR is a set of 60000  small (32x32) images with numerous classes such as dogs, cats, planes, and trucks.  The CIFAR10 dataset has 10 different classes of data.  The CIFAR100 dataset is an extension with 100 different classes of data.  In addtion, the ImageNet database is another dataset with which to test your skills.   </p>
</div></div></div></div><div class="end_space"></div></div>
        <div id="tooltip" class="ipython_tooltip" style="display:none"><div class="tooltipbuttons"><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" role="button" class="ui-button"><span class="ui-icon ui-icon-close">Close</span></a><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" class="ui-corner-all" role="button" id="expanbutton" title="Grow the tooltip vertically (press shift-tab twice)"><span class="ui-icon ui-icon-plus">Expand</span></a><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" role="button" class="ui-button" title="show the current docstring in pager (press shift-tab 4 times)"><span class="ui-icon ui-icon-arrowstop-l-n">Open in Pager</span></a><a href="http://ec2-54-168-239-174.ap-northeast-1.compute.amazonaws.com/L8Ljs7G2/notebooks/Getting%20Started%20with%20Deep%20Learning.ipynb#" role="button" class="ui-button" title="Tooltip will linger for 10 seconds while you type" style="display: none;"><span class="ui-icon ui-icon-clock">Close</span></a></div><div class="pretooltiparrow"></div><div class="tooltiptext smalltooltip"></div></div>
    </div>
</div>



</div>



<div id="pager" class="ui-resizable">
    <div id="pager-contents">
        <div id="pager-container" class="container"></div>
    </div>
    <div id="pager-button-area"><a role="button" title="Open the pager in an external window" class="ui-button"><span class="ui-icon ui-icon-extlink"></span></a><a role="button" title="Close the pager" class="ui-button"><span class="ui-icon ui-icon-close"></span></a></div>
<div class="ui-resizable-handle ui-resizable-n" style="z-index: 90;"></div></div>






<script type="text/javascript">
    sys_info = {"os_name": "posix", "sys_version": "2.7.6 (default, Jun 22 2015, 17:58:13) \n[GCC 4.8.2]", "default_encoding": "ANSI_X3.4-1968", "sys_platform": "linux2", "ipython_version": "3.2.1", "ipython_path": "/home/ubuntu/venv/lib/python2.7/site-packages/IPython", "commit_source": "installation", "platform": "Linux-3.13.0-46-generic-x86_64-with-Ubuntu-14.04-trusty", "sys_executable": "/home/ubuntu/venv/bin/python", "commit_hash": "2d95975"};
</script>

<script src="./Getting Started with Deep Learning_files/encoding.js" charset="utf-8"></script>

<script src="./Getting Started with Deep Learning_files/main.js" charset="utf-8"></script>





<div style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"><div id="MathJax_Font_Test" style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-family: STIXSizeOneSym, sans-serif;"></div></div><span style="border-radius: 2px; text-indent: 20px; width: auto; padding: 0px 4px 0px 0px; text-align: center; font-style: normal; font-variant: normal; font-weight: bold; font-stretch: normal; font-size: 11px; line-height: 20px; font-family: &quot;Helvetica Neue&quot;, Helvetica, sans-serif; color: rgb(255, 255, 255); position: absolute; opacity: 1; z-index: 8675309; display: none; cursor: pointer; border: none; -webkit-font-smoothing: antialiased; top: 3585px; left: 243px; background: url(&quot;data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMzBweCIgd2lkdGg9IjMwcHgiIHZpZXdCb3g9Ii0xIC0xIDMxIDMxIj48Zz48cGF0aCBkPSJNMjkuNDQ5LDE0LjY2MiBDMjkuNDQ5LDIyLjcyMiAyMi44NjgsMjkuMjU2IDE0Ljc1LDI5LjI1NiBDNi42MzIsMjkuMjU2IDAuMDUxLDIyLjcyMiAwLjA1MSwxNC42NjIgQzAuMDUxLDYuNjAxIDYuNjMyLDAuMDY3IDE0Ljc1LDAuMDY3IEMyMi44NjgsMC4wNjcgMjkuNDQ5LDYuNjAxIDI5LjQ0OSwxNC42NjIiIGZpbGw9IiNmZmYiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxIj48L3BhdGg+PHBhdGggZD0iTTE0LjczMywxLjY4NiBDNy41MTYsMS42ODYgMS42NjUsNy40OTUgMS42NjUsMTQuNjYyIEMxLjY2NSwyMC4xNTkgNS4xMDksMjQuODU0IDkuOTcsMjYuNzQ0IEM5Ljg1NiwyNS43MTggOS43NTMsMjQuMTQzIDEwLjAxNiwyMy4wMjIgQzEwLjI1MywyMi4wMSAxMS41NDgsMTYuNTcyIDExLjU0OCwxNi41NzIgQzExLjU0OCwxNi41NzIgMTEuMTU3LDE1Ljc5NSAxMS4xNTcsMTQuNjQ2IEMxMS4xNTcsMTIuODQyIDEyLjIxMSwxMS40OTUgMTMuNTIyLDExLjQ5NSBDMTQuNjM3LDExLjQ5NSAxNS4xNzUsMTIuMzI2IDE1LjE3NSwxMy4zMjMgQzE1LjE3NSwxNC40MzYgMTQuNDYyLDE2LjEgMTQuMDkzLDE3LjY0MyBDMTMuNzg1LDE4LjkzNSAxNC43NDUsMTkuOTg4IDE2LjAyOCwxOS45ODggQzE4LjM1MSwxOS45ODggMjAuMTM2LDE3LjU1NiAyMC4xMzYsMTQuMDQ2IEMyMC4xMzYsMTAuOTM5IDE3Ljg4OCw4Ljc2NyAxNC42NzgsOC43NjcgQzEwLjk1OSw4Ljc2NyA4Ljc3NywxMS41MzYgOC43NzcsMTQuMzk4IEM4Ljc3NywxNS41MTMgOS4yMSwxNi43MDkgOS43NDksMTcuMzU5IEM5Ljg1NiwxNy40ODggOS44NzIsMTcuNiA5Ljg0LDE3LjczMSBDOS43NDEsMTguMTQxIDkuNTIsMTkuMDIzIDkuNDc3LDE5LjIwMyBDOS40MiwxOS40NCA5LjI4OCwxOS40OTEgOS4wNCwxOS4zNzYgQzcuNDA4LDE4LjYyMiA2LjM4NywxNi4yNTIgNi4zODcsMTQuMzQ5IEM2LjM4NywxMC4yNTYgOS4zODMsNi40OTcgMTUuMDIyLDYuNDk3IEMxOS41NTUsNi40OTcgMjMuMDc4LDkuNzA1IDIzLjA3OCwxMy45OTEgQzIzLjA3OCwxOC40NjMgMjAuMjM5LDIyLjA2MiAxNi4yOTcsMjIuMDYyIEMxNC45NzMsMjIuMDYyIDEzLjcyOCwyMS4zNzkgMTMuMzAyLDIwLjU3MiBDMTMuMzAyLDIwLjU3MiAxMi42NDcsMjMuMDUgMTIuNDg4LDIzLjY1NyBDMTIuMTkzLDI0Ljc4NCAxMS4zOTYsMjYuMTk2IDEwLjg2MywyNy4wNTggQzEyLjA4NiwyNy40MzQgMTMuMzg2LDI3LjYzNyAxNC43MzMsMjcuNjM3IEMyMS45NSwyNy42MzcgMjcuODAxLDIxLjgyOCAyNy44MDEsMTQuNjYyIEMyNy44MDEsNy40OTUgMjEuOTUsMS42ODYgMTQuNzMzLDEuNjg2IiBmaWxsPSIjYmQwODFjIj48L3BhdGg+PC9nPjwvc3ZnPg==&quot;) 3px 50% / 14px 14px no-repeat rgb(189, 8, 28);">Save</span></body></html>